{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../../data/train_2016_v2.csv',parse_dates=['transactiondate'])\n",
    "prop = pd.read_csv('../../data/properties_2016.csv')\n",
    "sample = pd.read_csv('../../data/sample_submission.csv')\n",
    "sample['parcelid'] = sample['ParcelId']\n",
    "sample.drop('ParcelId',axis = 1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c, dtype in zip(prop.columns, prop.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        prop[c] = prop[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = train.merge(prop, how='left', on='parcelid')\n",
    "df_test = sample.merge(prop, how='left', on='parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    90026\n",
      "2      123\n",
      "3        1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parcelid_count = df_train['parcelid'].value_counts().reset_index()\n",
    "df_parcelid_count.columns = ['parcelid','count']\n",
    "print(df_parcelid_count['count'].value_counts())\n",
    "del df_parcelid_count; gc.collect()\n",
    "## most of parcelid is unique, that is to say few properties(124 parcelid) were sold multiple times during 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "2985217\n",
      "2895067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parcelid_train = np.unique(df_train['parcelid'])\n",
    "print(len(df_train))\n",
    "print(len(df_test))\n",
    "print(len(df_test[df_test['parcelid'].isin(parcelid_train) == False]))\n",
    "del parcelid_train; gc.collect()\n",
    "## all of parcelid showed in train need to be predicted in time point 201610 201611 201612\n",
    "## the others are unkown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "def GenerateLastGap(data):\n",
    "    result = pd.Series(index = data.index)\n",
    "    for i in data.index:\n",
    "        if((i == 0) or (data.at[i,'parcelid'] != data.at[i - 1,'parcelid'])):\n",
    "            result[i] = 0\n",
    "        else:\n",
    "            result[i] = data.at[i,'transactiondate'].month - data.at[i - 1,'transactiondate'].month\n",
    "    return result\n",
    "## last gap for train\n",
    "df_train_lastgap = df_train.sort_values(['parcelid','transactiondate'],inplace= False)\n",
    "df_train_lastgap['idx'] = range(len(df_train_lastgap))\n",
    "df_tmp = df_train_lastgap[['idx','parcelid','transactiondate']].set_index(['idx'])\n",
    "df_lastgap = pd.DataFrame(GenerateLastGap(df_tmp),columns= ['lastgap']).reset_index()\n",
    "df_train_lastgap = df_train_lastgap.merge(df_lastgap,on='idx',how='left')\n",
    "df_train_lastgap.drop(['idx'],inplace=True,axis = 1)\n",
    "df_train = df_train_lastgap.copy()\n",
    "del df_train_lastgap,df_tmp,df_lastgap; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## last gap for test\n",
    "df_latest_transaction = df_train.groupby(['parcelid'])['transactiondate'].max().to_frame().reset_index()\n",
    "df_latest_transaction.columns = ['parcelid','lasttransactiondate']\n",
    "df_test_lastgap = df_test.merge(df_latest_transaction,on = 'parcelid',how = 'left')\n",
    "l_test_transdate = ['201610','201611','201612','201710','201711','201712']\n",
    "for d in l_test_transdate:\n",
    "    mt = datetime.datetime.strptime(d,'%Y%m').month\n",
    "    df_test_lastgap['lastgap%s' % d] = df_test_lastgap['lasttransactiondate'].apply(lambda v: 0 if(pd.isnull(v)) else (mt - v.month))\n",
    "df_test_lastgap[df_test_lastgap['lastgap201610'] > 0].head(20)\n",
    "df_test = df_test_lastgap.copy()\n",
    "del df_latest_transaction,df_test_lastgap;gc.collect()\n",
    "#df_train_lastgap[df_train_lastgap['lastgap'] > 0]['parcelid']\n",
    "#print(df_train_lastgap[df_train_lastgap['parcelid'] == 10799924])\n",
    "#print(tmp.ix[10799924])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column_name</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>architecturalstyletypeid</td>\n",
       "      <td>90014</td>\n",
       "      <td>0.997109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>basementsqft</td>\n",
       "      <td>90232</td>\n",
       "      <td>0.999524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>buildingclasstypeid</td>\n",
       "      <td>90259</td>\n",
       "      <td>0.999823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>finishedsquarefeet13</td>\n",
       "      <td>90242</td>\n",
       "      <td>0.999634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>finishedsquarefeet6</td>\n",
       "      <td>89854</td>\n",
       "      <td>0.995336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>storytypeid</td>\n",
       "      <td>90232</td>\n",
       "      <td>0.999524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>typeconstructiontypeid</td>\n",
       "      <td>89976</td>\n",
       "      <td>0.996688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>yardbuildingsqft26</td>\n",
       "      <td>90180</td>\n",
       "      <td>0.998948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>fireplaceflag</td>\n",
       "      <td>90053</td>\n",
       "      <td>0.997541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 column_name  missing_count  missing_ratio\n",
       "4   architecturalstyletypeid          90014       0.997109\n",
       "5               basementsqft          90232       0.999524\n",
       "8        buildingclasstypeid          90259       0.999823\n",
       "15      finishedsquarefeet13          90242       0.999634\n",
       "18       finishedsquarefeet6          89854       0.995336\n",
       "43               storytypeid          90232       0.999524\n",
       "45    typeconstructiontypeid          89976       0.996688\n",
       "48        yardbuildingsqft26          90180       0.998948\n",
       "51             fireplaceflag          90053       0.997541"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df = df_train.isnull().sum(axis=0).reset_index()\n",
    "missing_df.columns = ['column_name', 'missing_count']\n",
    "missing_df['missing_ratio'] = missing_df['missing_count'] / df_train.shape[0]\n",
    "missing_df.ix[missing_df['missing_ratio']>0.995]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hashottuborspa', 'propertycountylandusecode', 'propertyzoningdesc', 'fireplaceflag', 'taxdelinquencyflag']\n"
     ]
    }
   ],
   "source": [
    "ObjectColumns = []\n",
    "for c, dtype in zip(df_train.columns, df_train.dtypes):\n",
    "    if dtype == np.float64:\n",
    "        df_train[c] = df_train[c].astype(np.float32)\n",
    "    elif dtype == np.object:\n",
    "        ObjectColumns.append(c)\n",
    "df_train.dtypes.value_counts()\n",
    "print(ObjectColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hashottuborspa\n",
    "NewCols = [col for col in df_train['hashottuborspa'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['hashottuborspa-%s' % k] = 0\n",
    "    df_train.loc[df_train['hashottuborspa'] == k,'hashottuborspa-%s' % k] = 1\n",
    "df_train['hashottuborspa-Missing'] = 0\n",
    "df_train.loc[df_train['hashottuborspa'].isnull() == True,'hashottuborspa-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'hashottuborspa' in col]]['hashottuborspa-True'].value_counts()\n",
    "df_train = df_train.drop(['hashottuborspa'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n"
     ]
    }
   ],
   "source": [
    "# fireplaceflag\n",
    "print(len(df_train))\n",
    "NewCols = [col for col in df_train['fireplaceflag'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['fireplaceflag-%s' % k] = 0\n",
    "    df_train.loc[df_train['fireplaceflag'] == k,'fireplaceflag-%s' % k] = 1\n",
    "df_train['fireplaceflag-Missing'] = 0\n",
    "df_train.loc[df_train['fireplaceflag'].isnull() == True,'fireplaceflag-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'fireplaceflag' in col]]['fireplaceflag-True'].value_counts()\n",
    "df_train = df_train.drop(['fireplaceflag'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# taxdelinquencyflag\n",
    "NewCols = [col for col in df_train['taxdelinquencyflag'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['taxdelinquencyflag-%s' % k] = 0\n",
    "    df_train.loc[df_train['taxdelinquencyflag'] == k,'taxdelinquencyflag-%s' % k] = 1\n",
    "df_train['taxdelinquencyflag-Missing'] = 0\n",
    "df_train.loc[df_train['taxdelinquencyflag'].isnull() == True,'taxdelinquencyflag-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'taxdelinquencyflag' in col]]['taxdelinquencyflag-Y'].value_counts()\n",
    "df_train = df_train.drop(['taxdelinquencyflag'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logerror', 'airconditioningtypeid', 'architecturalstyletypeid', 'basementsqft', 'bathroomcnt', 'bedroomcnt', 'buildingclasstypeid', 'buildingqualitytypeid', 'calculatedbathnbr', 'decktypeid', 'finishedfloor1squarefeet', 'calculatedfinishedsquarefeet', 'finishedsquarefeet12', 'finishedsquarefeet13', 'finishedsquarefeet15', 'finishedsquarefeet50', 'finishedsquarefeet6', 'fips', 'fireplacecnt', 'fullbathcnt', 'garagecarcnt', 'garagetotalsqft', 'heatingorsystemtypeid', 'latitude', 'longitude', 'lotsizesquarefeet', 'poolcnt', 'poolsizesum', 'pooltypeid10', 'pooltypeid2', 'pooltypeid7', 'propertylandusetypeid', 'rawcensustractandblock', 'regionidcity', 'regionidcounty', 'regionidneighborhood', 'regionidzip', 'roomcnt', 'storytypeid', 'threequarterbathnbr', 'typeconstructiontypeid', 'unitcnt', 'yardbuildingsqft17', 'yardbuildingsqft26', 'yearbuilt', 'numberofstories', 'structuretaxvaluedollarcnt', 'taxvaluedollarcnt', 'assessmentyear', 'landtaxvaluedollarcnt', 'taxamount', 'taxdelinquencyyear', 'censustractandblock', 'lastgap']\n"
     ]
    }
   ],
   "source": [
    "OrdinalCols = []\n",
    "for c, dtype in zip(df_train.columns, df_train.dtypes):\n",
    "    if dtype == np.float32:\n",
    "        OrdinalCols.append(c)\n",
    "print(OrdinalCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "1.0     26668\n",
      "13.0     1833\n",
      "5.0       215\n",
      "11.0       63\n",
      "9.0         1\n",
      "3.0         1\n",
      "Name: airconditioningtypeid, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# airconditioningtypeid\n",
    "print(len(df_train))\n",
    "print(df_train['airconditioningtypeid'].value_counts())\n",
    "NewCols = [col for col in df_train['airconditioningtypeid'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['airconditioningtypeid-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['airconditioningtypeid'] == k,'airconditioningtypeid-%s' % str(int(k))] = 1\n",
    "df_train['airconditioningtypeid-Missing'] = 0\n",
    "df_train.loc[df_train['airconditioningtypeid'].isnull() == True,'airconditioningtypeid-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'airconditioningtypeid' in col]]['airconditioningtypeid-13'].value_counts()\n",
    "df_train = df_train.drop(['airconditioningtypeid'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'architecturalstyletypeid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'architecturalstyletypeid'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-60783613bffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# architecturalstyletypeid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'architecturalstyletypeid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mNewCols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'architecturalstyletypeid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mNewCols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/site-packages/pandas/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'architecturalstyletypeid'"
     ]
    }
   ],
   "source": [
    "# architecturalstyletypeid\n",
    "print(len(df_train))\n",
    "print(df_train['architecturalstyletypeid'].value_counts())\n",
    "NewCols = [col for col in df_train['architecturalstyletypeid'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['architecturalstyletypeid-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['architecturalstyletypeid'] == k,'architecturalstyletypeid-%s' % str(int(k))] = 1\n",
    "df_train['architecturalstyletypeid-Missing'] = 0\n",
    "df_train.loc[df_train['architecturalstyletypeid'].isnull() == True,'architecturalstyletypeid-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'architecturalstyletypeid' in col]]['airconditioningtypeid-13'].value_counts()\n",
    "df_train = df_train.drop(['airconditioningtypeid'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "7.0     29310\n",
      "4.0     23839\n",
      "1.0      2627\n",
      "10.0     1461\n",
      "12.0      119\n",
      "8.0         5\n",
      "6.0         2\n",
      "11.0        1\n",
      "Name: buildingqualitytypeid, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# buildingqualitytypeid\n",
    "print(len(df_train))\n",
    "print(df_train['buildingqualitytypeid'].value_counts())\n",
    "NewCols = [col for col in df_train['buildingqualitytypeid'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['buildingqualitytypeid-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['buildingqualitytypeid'] == k,'buildingqualitytypeid-%s' % str(int(k))] = 1\n",
    "df_train['buildingqualitytypeid-Missing'] = 0\n",
    "df_train.loc[df_train['buildingqualitytypeid'].isnull() == True,'buildingqualitytypeid-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'buildingqualitytypeid' in col]]['buildingqualitytypeid-8'].value_counts()\n",
    "df_train = df_train.drop(['buildingqualitytypeid'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "66.0    658\n",
      "Name: decktypeid, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# decktypeid\n",
    "print(len(df_train))\n",
    "print(df_train['decktypeid'].value_counts())\n",
    "NewCols = [col for col in df_train['decktypeid'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['decktypeid-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['decktypeid'] == k,'decktypeid-%s' % str(int(k))] = 1\n",
    "df_train['decktypeid-Missing'] = 0\n",
    "df_train.loc[df_train['decktypeid'].isnull() == True,'decktypeid-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'decktypeid' in col]]['decktypeid-66'].value_counts()\n",
    "df_train = df_train.drop(['decktypeid'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "6037.0    58574\n",
      "6059.0    24505\n",
      "6111.0     7196\n",
      "Name: fips, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# fips\n",
    "print(len(df_train))\n",
    "print(df_train['fips'].value_counts())\n",
    "NewCols = [col for col in df_train['fips'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['fips-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['fips'] == k,'fips-%s' % str(int(k))] = 1\n",
    "df_train['fips-Missing'] = 0\n",
    "df_train.loc[df_train['fips'].isnull() == True,'fips-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'fips' in col]]['fips-6059'].value_counts()\n",
    "df_train = df_train.drop(['fips'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "2.0     38303\n",
      "7.0     15519\n",
      "24.0     1071\n",
      "6.0       970\n",
      "20.0       97\n",
      "13.0       76\n",
      "18.0       25\n",
      "1.0        13\n",
      "14.0        2\n",
      "10.0        2\n",
      "12.0        1\n",
      "11.0        1\n",
      "Name: heatingorsystemtypeid, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# heatingorsystemtypeid\n",
    "print(len(df_train))\n",
    "print(df_train['heatingorsystemtypeid'].value_counts())\n",
    "NewCols = [col for col in df_train['heatingorsystemtypeid'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['heatingorsystemtypeid-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['heatingorsystemtypeid'] == k,'heatingorsystemtypeid-%s' % str(int(k))] = 1\n",
    "df_train['heatingorsystemtypeid-Missing'] = 0\n",
    "df_train.loc[df_train['heatingorsystemtypeid'].isnull() == True,'heatingorsystemtypeid-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'heatingorsystemtypeid' in col]]['heatingorsystemtypeid-7'].value_counts()\n",
    "df_train = df_train.drop(['heatingorsystemtypeid'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "1.0    1161\n",
      "Name: pooltypeid10, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pooltypeid10\n",
    "print(len(df_train))\n",
    "print(df_train['pooltypeid10'].value_counts())\n",
    "NewCols = [col for col in df_train['pooltypeid10'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['pooltypeid10-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['pooltypeid10'] == k,'pooltypeid10-%s' % str(int(k))] = 1\n",
    "df_train['pooltypeid10-Missing'] = 0\n",
    "df_train.loc[df_train['pooltypeid10'].isnull() == True,'pooltypeid10-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'pooltypeid10' in col]]['pooltypeid10-1'].value_counts()\n",
    "df_train = df_train.drop(['pooltypeid10'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "1.0    1204\n",
      "Name: pooltypeid2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pooltypeid2\n",
    "print(len(df_train))\n",
    "print(df_train['pooltypeid2'].value_counts())\n",
    "NewCols = [col for col in df_train['pooltypeid2'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['pooltypeid2-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['pooltypeid2'] == k,'pooltypeid2-%s' % str(int(k))] = 1\n",
    "df_train['pooltypeid2-Missing'] = 0\n",
    "df_train.loc[df_train['pooltypeid2'].isnull() == True,'pooltypeid2-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'pooltypeid2' in col]]['pooltypeid2-1'].value_counts()\n",
    "df_train = df_train.drop(['pooltypeid2'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "1.0    16697\n",
      "Name: pooltypeid7, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pooltypeid7\n",
    "print(len(df_train))\n",
    "print(df_train['pooltypeid7'].value_counts())\n",
    "NewCols = [col for col in df_train['pooltypeid7'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['pooltypeid7-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['pooltypeid7'] == k,'pooltypeid7-%s' % str(int(k))] = 1\n",
    "df_train['pooltypeid7-Missing'] = 0\n",
    "df_train.loc[df_train['pooltypeid7'].isnull() == True,'pooltypeid7-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'pooltypeid7' in col]]['pooltypeid7-1'].value_counts()\n",
    "df_train = df_train.drop(['pooltypeid7'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "261.0    60637\n",
      "266.0    22815\n",
      "246.0     2376\n",
      "269.0     2334\n",
      "248.0      879\n",
      "247.0      629\n",
      "265.0      356\n",
      "263.0       84\n",
      "260.0       62\n",
      "275.0       46\n",
      "267.0       28\n",
      "31.0        17\n",
      "264.0       11\n",
      "47.0         1\n",
      "Name: propertylandusetypeid, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# propertylandusetypeid\n",
    "print(len(df_train))\n",
    "print(df_train['propertylandusetypeid'].value_counts())\n",
    "NewCols = [col for col in df_train['propertylandusetypeid'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['propertylandusetypeid-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['propertylandusetypeid'] == k,'propertylandusetypeid-%s' % str(int(k))] = 1\n",
    "df_train['propertylandusetypeid-Missing'] = 0\n",
    "df_train.loc[df_train['propertylandusetypeid'].isnull() == True,'propertylandusetypeid-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'propertylandusetypeid' in col]]['propertylandusetypeid-269'].value_counts()\n",
    "df_train = df_train.drop(['propertylandusetypeid'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "60590320.0    3297\n",
      "60590628.0    2665\n",
      "60590524.0    2404\n",
      "60379200.0    2201\n",
      "60590424.0    2113\n",
      "60590220.0    1763\n",
      "60590992.0    1405\n",
      "61110076.0    1334\n",
      "60379108.0    1126\n",
      "60379104.0    1010\n",
      "60378004.0     980\n",
      "60590756.0     937\n",
      "60590996.0     919\n",
      "60379012.0     880\n",
      "60590016.0     856\n",
      "60591100.0     833\n",
      "60379204.0     832\n",
      "61110052.0     758\n",
      "60374032.0     758\n",
      "60379008.0     701\n",
      "60590116.0     597\n",
      "61110060.0     594\n",
      "60590760.0     559\n",
      "60590632.0     528\n",
      "60376704.0     498\n",
      "60590420.0     494\n",
      "61110084.0     488\n",
      "60374004.0     473\n",
      "60371396.0     470\n",
      "60376212.0     440\n",
      "              ... \n",
      "60371840.0      19\n",
      "60371904.0      19\n",
      "60372240.0      18\n",
      "60372228.0      16\n",
      "60372100.0      16\n",
      "60372000.0      15\n",
      "60371880.0      15\n",
      "60379304.0      15\n",
      "60372032.0      14\n",
      "60372268.0      13\n",
      "60372096.0      12\n",
      "60375756.0      11\n",
      "60372136.0      11\n",
      "60371928.0      11\n",
      "60372416.0      10\n",
      "60376100.0      10\n",
      "60371996.0      10\n",
      "60372280.0       9\n",
      "60372144.0       9\n",
      "60372092.0       9\n",
      "60379800.0       7\n",
      "60372264.0       6\n",
      "61110092.0       5\n",
      "60372052.0       5\n",
      "60372248.0       5\n",
      "60372260.0       4\n",
      "60372272.0       4\n",
      "61110000.0       3\n",
      "60372152.0       1\n",
      "60379300.0       1\n",
      "Name: rawcensustractandblock, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# rawcensustractandblock\n",
    "print(len(df_train))\n",
    "print(df_train['rawcensustractandblock'].value_counts())\n",
    "NewCols = [col for col in df_train['rawcensustractandblock'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['rawcensustractandblock-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['rawcensustractandblock'] == k,'rawcensustractandblock-%s' % str(int(k))] = 1\n",
    "df_train['rawcensustractandblock-Missing'] = 0\n",
    "df_train.loc[df_train['rawcensustractandblock'].isnull() == True,'rawcensustractandblock-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'rawcensustractandblock' in col]]['rawcensustractandblock-60378004'].value_counts()\n",
    "df_train = df_train.drop(['rawcensustractandblock'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "12447.0     20559\n",
      "46298.0      3000\n",
      "52650.0      2132\n",
      "54311.0      2128\n",
      "5534.0       2035\n",
      "40227.0      1949\n",
      "16764.0      1800\n",
      "25218.0      1586\n",
      "34278.0      1383\n",
      "27110.0      1266\n",
      "12773.0      1222\n",
      "47019.0      1187\n",
      "13150.0      1120\n",
      "47568.0      1097\n",
      "45457.0      1052\n",
      "24812.0      1037\n",
      "33252.0      1034\n",
      "34543.0       949\n",
      "51239.0       932\n",
      "54722.0       929\n",
      "53571.0       923\n",
      "25459.0       904\n",
      "24832.0       891\n",
      "32380.0       820\n",
      "13693.0       815\n",
      "37086.0       791\n",
      "33612.0       772\n",
      "20008.0       756\n",
      "21412.0       729\n",
      "15554.0       693\n",
      "            ...  \n",
      "21778.0        50\n",
      "30399.0        49\n",
      "113412.0       47\n",
      "118875.0       40\n",
      "16961.0        39\n",
      "16389.0        36\n",
      "272578.0       33\n",
      "32753.0        30\n",
      "3491.0         30\n",
      "25468.0        27\n",
      "38980.0        25\n",
      "6822.0         24\n",
      "13232.0        21\n",
      "42091.0        20\n",
      "114834.0       18\n",
      "34037.0        16\n",
      "25271.0        14\n",
      "33312.0        14\n",
      "25621.0        14\n",
      "14906.0        13\n",
      "31134.0        12\n",
      "53162.0         9\n",
      "32927.0         5\n",
      "10815.0         4\n",
      "118880.0        4\n",
      "21395.0         3\n",
      "13311.0         3\n",
      "24797.0         2\n",
      "6285.0          1\n",
      "37882.0         1\n",
      "Name: regionidcity, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# regionidcity\n",
    "print(len(df_train))\n",
    "print(df_train['regionidcity'].value_counts())\n",
    "NewCols = [col for col in df_train['regionidcity'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['regionidcity-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['regionidcity'] == k,'regionidcity-%s' % str(int(k))] = 1\n",
    "df_train['regionidcity-Missing'] = 0\n",
    "df_train.loc[df_train['regionidcity'].isnull() == True,'regionidcity-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'regionidcity' in col]]['regionidcity-47568'].value_counts()\n",
    "df_train = df_train.drop(['regionidcity'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "3101.0    58574\n",
      "1286.0    24505\n",
      "2061.0     7196\n",
      "Name: regionidcounty, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# regionidcounty\n",
    "print(len(df_train))\n",
    "print(df_train['regionidcounty'].value_counts())\n",
    "NewCols = [col for col in df_train['regionidcounty'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['regionidcounty-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['regionidcounty'] == k,'regionidcounty-%s' % str(int(k))] = 1\n",
    "df_train['regionidcounty-Missing'] = 0\n",
    "df_train.loc[df_train['regionidcounty'].isnull() == True,'regionidcounty-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'regionidcounty' in col]]['regionidcounty-1286'].value_counts()\n",
    "df_train = df_train.drop(['regionidcounty'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "118208.0    773\n",
      "27080.0     755\n",
      "48570.0     753\n",
      "37739.0     715\n",
      "48200.0     653\n",
      "268496.0    631\n",
      "51906.0     609\n",
      "54300.0     540\n",
      "113455.0    529\n",
      "33183.0     497\n",
      "274049.0    479\n",
      "34213.0     477\n",
      "46736.0     454\n",
      "47880.0     450\n",
      "47950.0     428\n",
      "31817.0     417\n",
      "113910.0    409\n",
      "6952.0      408\n",
      "274514.0    403\n",
      "40548.0     397\n",
      "118920.0    391\n",
      "41131.0     371\n",
      "268588.0    370\n",
      "26134.0     352\n",
      "276476.0    352\n",
      "21056.0     341\n",
      "41466.0     334\n",
      "19810.0     332\n",
      "32059.0     308\n",
      "27987.0     299\n",
      "           ... \n",
      "761214.0      1\n",
      "273607.0      1\n",
      "260382.0      1\n",
      "761098.0      1\n",
      "763217.0      1\n",
      "761090.0      1\n",
      "763791.0      1\n",
      "764140.0      1\n",
      "416332.0      1\n",
      "272732.0      1\n",
      "762937.0      1\n",
      "275287.0      1\n",
      "273313.0      1\n",
      "762932.0      1\n",
      "762929.0      1\n",
      "762927.0      1\n",
      "764138.0      1\n",
      "764136.0      1\n",
      "762947.0      1\n",
      "268446.0      1\n",
      "762949.0      1\n",
      "416335.0      1\n",
      "762955.0      1\n",
      "764152.0      1\n",
      "762960.0      1\n",
      "764165.0      1\n",
      "762191.0      1\n",
      "272170.0      1\n",
      "764139.0      1\n",
      "762963.0      1\n",
      "Name: regionidneighborhood, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# regionidneighborhood\n",
    "print(len(df_train))\n",
    "print(df_train['regionidneighborhood'].value_counts())\n",
    "NewCols = [col for col in df_train['regionidneighborhood'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['regionidneighborhood-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['regionidneighborhood'] == k,'regionidneighborhood-%s' % str(int(k))] = 1\n",
    "df_train['regionidneighborhood-Missing'] = 0\n",
    "df_train.loc[df_train['regionidneighborhood'].isnull() == True,'regionidneighborhood-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'regionidneighborhood' in col]]['regionidneighborhood-274049'].value_counts()\n",
    "df_train = df_train.drop(['regionidneighborhood'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "97319.0     912\n",
      "96987.0     902\n",
      "96974.0     824\n",
      "97329.0     760\n",
      "97318.0     726\n",
      "97118.0     719\n",
      "97328.0     704\n",
      "96993.0     687\n",
      "96996.0     640\n",
      "96962.0     624\n",
      "96193.0     593\n",
      "96995.0     570\n",
      "96368.0     560\n",
      "97116.0     546\n",
      "96385.0     521\n",
      "96964.0     516\n",
      "96998.0     513\n",
      "96505.0     512\n",
      "96954.0     511\n",
      "96989.0     504\n",
      "96373.0     500\n",
      "97091.0     498\n",
      "96186.0     494\n",
      "96377.0     493\n",
      "96364.0     476\n",
      "96389.0     474\n",
      "97078.0     474\n",
      "97083.0     464\n",
      "96351.0     456\n",
      "96236.0     449\n",
      "           ... \n",
      "96038.0      37\n",
      "96986.0      35\n",
      "96135.0      35\n",
      "96323.0      33\n",
      "96980.0      33\n",
      "96207.0      32\n",
      "97037.0      32\n",
      "96119.0      30\n",
      "96434.0      30\n",
      "96021.0      29\n",
      "96973.0      27\n",
      "96951.0      26\n",
      "97316.0      26\n",
      "95998.0      21\n",
      "97331.0      20\n",
      "95991.0      18\n",
      "97119.0      17\n",
      "97324.0      16\n",
      "399675.0     13\n",
      "95995.0      12\n",
      "96148.0      11\n",
      "97108.0       6\n",
      "96329.0       5\n",
      "96002.0       4\n",
      "96039.0       3\n",
      "96500.0       2\n",
      "96034.0       1\n",
      "97111.0       1\n",
      "96467.0       1\n",
      "96226.0       1\n",
      "Name: regionidzip, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# regionidzip\n",
    "print(len(df_train))\n",
    "print(df_train['regionidzip'].value_counts())\n",
    "NewCols = [col for col in df_train['regionidzip'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['regionidzip-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['regionidzip'] == k,'regionidzip-%s' % str(int(k))] = 1\n",
    "df_train['regionidzip-Missing'] = 0\n",
    "df_train.loc[df_train['regionidzip'].isnull() == True,'regionidzip-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'regionidzip' in col]]['regionidzip-97329'].value_counts()\n",
    "df_train = df_train.drop(['regionidzip'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "6.0     296\n",
      "4.0       2\n",
      "13.0      1\n",
      "Name: typeconstructiontypeid, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# typeconstructiontypeid\n",
    "print(len(df_train))\n",
    "print(df_train['typeconstructiontypeid'].value_counts())\n",
    "NewCols = [col for col in df_train['typeconstructiontypeid'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['typeconstructiontypeid-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['typeconstructiontypeid'] == k,'typeconstructiontypeid-%s' % str(int(k))] = 1\n",
    "df_train['typeconstructiontypeid-Missing'] = 0\n",
    "df_train.loc[df_train['typeconstructiontypeid'].isnull() == True,'typeconstructiontypeid-Missing'] = 1\n",
    "df_train[[col  for col in df_train.columns if 'typeconstructiontypeid' in col]]['typeconstructiontypeid-4'].value_counts()\n",
    "df_train = df_train.drop(['typeconstructiontypeid'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "6.059032e+13    3268\n",
      "6.059063e+13    2610\n",
      "6.059053e+13    2345\n",
      "6.037920e+13    2118\n",
      "6.059042e+13    1809\n",
      "6.059022e+13    1753\n",
      "6.059099e+13    1400\n",
      "6.059076e+13    1159\n",
      "6.037911e+13    1112\n",
      "6.111007e+13    1018\n",
      "6.037901e+13    1007\n",
      "6.037910e+13     983\n",
      "6.059110e+13     945\n",
      "6.037901e+13     924\n",
      "6.059100e+13     919\n",
      "6.037403e+13     905\n",
      "6.037920e+13     831\n",
      "6.059042e+13     797\n",
      "6.111005e+13     780\n",
      "6.111008e+13     765\n",
      "6.037800e+13     745\n",
      "6.111006e+13     646\n",
      "6.037620e+13     595\n",
      "6.037670e+13     582\n",
      "6.059002e+13     576\n",
      "6.059001e+13     563\n",
      "6.037409e+13     526\n",
      "6.059063e+13     513\n",
      "6.037113e+13     478\n",
      "6.059076e+13     474\n",
      "                ... \n",
      "6.037292e+13      21\n",
      "6.037202e+13      21\n",
      "6.111009e+13      20\n",
      "6.037200e+13      20\n",
      "6.037208e+13      20\n",
      "6.037233e+13      18\n",
      "6.037222e+13      18\n",
      "6.037210e+13      15\n",
      "6.037182e+13      14\n",
      "6.037203e+13      14\n",
      "6.037191e+13      14\n",
      "6.037121e+13      13\n",
      "6.037227e+13      13\n",
      "6.037278e+13      12\n",
      "6.037209e+13      12\n",
      "6.037277e+13      12\n",
      "6.037224e+13      11\n",
      "6.037228e+13      10\n",
      "6.037610e+13      10\n",
      "6.037209e+13       9\n",
      "6.037930e+13       7\n",
      "6.037226e+13       6\n",
      "6.037225e+13       5\n",
      "6.037205e+13       5\n",
      "6.071002e+13       5\n",
      "6.037980e+13       5\n",
      "6.037227e+13       4\n",
      "6.037226e+13       4\n",
      "6.037207e+13       2\n",
      "6.071004e+13       1\n",
      "Name: censustractandblock, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# censustractandblock\n",
    "print(len(df_train))\n",
    "print(df_train['censustractandblock'].value_counts())\n",
    "NewCols = [col for col in df_train['censustractandblock'].value_counts().keys()]\n",
    "for k in NewCols:\n",
    "    df_train['censustractandblock-%s' % str(int(k))] = 0\n",
    "    df_train.loc[df_train['censustractandblock'] == k,'censustractandblock-%s' % str(int(k))] = 1\n",
    "df_train['censustractandblock-Missing'] = 0\n",
    "df_train.loc[df_train['censustractandblock'].isnull() == True,'censustractandblock-Missing'] = 1\n",
    "#df_train[[col  for col in df_train.columns if 'censustractandblock' in col]]['censustractandblock-4'].value_counts()\n",
    "df_train = df_train.drop(['censustractandblock'],axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "1955.0    2261\n",
      "1989.0    2058\n",
      "1950.0    1994\n",
      "1954.0    1940\n",
      "1964.0    1919\n",
      "1973.0    1818\n",
      "1956.0    1760\n",
      "1979.0    1671\n",
      "1953.0    1661\n",
      "1987.0    1635\n",
      "1990.0    1620\n",
      "1963.0    1541\n",
      "1980.0    1518\n",
      "1986.0    1505\n",
      "1977.0    1489\n",
      "1951.0    1456\n",
      "1965.0    1449\n",
      "1985.0    1435\n",
      "1952.0    1434\n",
      "1972.0    1429\n",
      "1974.0    1385\n",
      "1978.0    1378\n",
      "1948.0    1346\n",
      "1981.0    1324\n",
      "1947.0    1310\n",
      "1971.0    1291\n",
      "1984.0    1282\n",
      "1988.0    1264\n",
      "1976.0    1249\n",
      "1957.0    1239\n",
      "          ... \n",
      "1919.0      99\n",
      "1907.0      94\n",
      "1933.0      83\n",
      "1909.0      79\n",
      "1906.0      76\n",
      "1916.0      74\n",
      "1905.0      69\n",
      "1918.0      67\n",
      "1934.0      62\n",
      "1917.0      56\n",
      "1901.0      41\n",
      "1903.0      36\n",
      "1902.0      26\n",
      "1904.0      25\n",
      "2015.0      23\n",
      "1890.0      18\n",
      "1895.0      16\n",
      "1900.0      13\n",
      "1898.0      10\n",
      "1899.0       6\n",
      "1885.0       6\n",
      "1896.0       5\n",
      "1894.0       5\n",
      "1897.0       3\n",
      "1893.0       3\n",
      "1892.0       3\n",
      "1888.0       2\n",
      "1891.0       1\n",
      "1887.0       1\n",
      "1886.0       1\n",
      "Name: yearbuilt, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(df_train['yearbuilt'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90275, 52) (90275,)\n",
      "[1]\tvalid_0's l2: 0.0126519\n",
      "[2]\tvalid_0's l2: 0.0126524\n",
      "[3]\tvalid_0's l2: 0.0126567\n",
      "[4]\tvalid_0's l2: 0.0126572\n",
      "[5]\tvalid_0's l2: 0.0126568\n",
      "[6]\tvalid_0's l2: 0.0126603\n",
      "[7]\tvalid_0's l2: 0.0126576\n",
      "[8]\tvalid_0's l2: 0.0126571\n",
      "[9]\tvalid_0's l2: 0.0126543\n",
      "[10]\tvalid_0's l2: 0.0126586\n",
      "[11]\tvalid_0's l2: 0.0126602\n",
      "[12]\tvalid_0's l2: 0.0126586\n",
      "[13]\tvalid_0's l2: 0.0126543\n",
      "[14]\tvalid_0's l2: 0.0126476\n",
      "[15]\tvalid_0's l2: 0.0126428\n",
      "[16]\tvalid_0's l2: 0.0126475\n",
      "[17]\tvalid_0's l2: 0.012646\n",
      "[18]\tvalid_0's l2: 0.0126485\n",
      "[19]\tvalid_0's l2: 0.0126451\n",
      "[20]\tvalid_0's l2: 0.0126503\n",
      "[21]\tvalid_0's l2: 0.0126534\n",
      "[22]\tvalid_0's l2: 0.012654\n",
      "[23]\tvalid_0's l2: 0.0126536\n",
      "[24]\tvalid_0's l2: 0.0126537\n",
      "[25]\tvalid_0's l2: 0.0126517\n",
      "[26]\tvalid_0's l2: 0.0126554\n",
      "[27]\tvalid_0's l2: 0.0126592\n",
      "[28]\tvalid_0's l2: 0.012661\n",
      "[29]\tvalid_0's l2: 0.0126592\n",
      "[30]\tvalid_0's l2: 0.0126616\n",
      "[31]\tvalid_0's l2: 0.0126601\n",
      "[32]\tvalid_0's l2: 0.0126619\n",
      "[33]\tvalid_0's l2: 0.012664\n",
      "[34]\tvalid_0's l2: 0.0126635\n",
      "[35]\tvalid_0's l2: 0.0126662\n",
      "[36]\tvalid_0's l2: 0.0126735\n",
      "[37]\tvalid_0's l2: 0.0126798\n",
      "[38]\tvalid_0's l2: 0.0126875\n",
      "[39]\tvalid_0's l2: 0.0126898\n",
      "[40]\tvalid_0's l2: 0.0126945\n",
      "[41]\tvalid_0's l2: 0.0126977\n",
      "[42]\tvalid_0's l2: 0.0126981\n",
      "[43]\tvalid_0's l2: 0.0127023\n",
      "[44]\tvalid_0's l2: 0.0127042\n",
      "[45]\tvalid_0's l2: 0.0127067\n",
      "[46]\tvalid_0's l2: 0.0127093\n",
      "[47]\tvalid_0's l2: 0.0127108\n",
      "[48]\tvalid_0's l2: 0.0127107\n",
      "[49]\tvalid_0's l2: 0.0127103\n",
      "[50]\tvalid_0's l2: 0.0127088\n",
      "[51]\tvalid_0's l2: 0.0127098\n",
      "[52]\tvalid_0's l2: 0.0127122\n",
      "[53]\tvalid_0's l2: 0.012712\n",
      "[54]\tvalid_0's l2: 0.0127125\n",
      "[55]\tvalid_0's l2: 0.0127138\n",
      "[56]\tvalid_0's l2: 0.0127164\n",
      "[57]\tvalid_0's l2: 0.0127191\n",
      "[58]\tvalid_0's l2: 0.0127193\n",
      "[59]\tvalid_0's l2: 0.0127203\n",
      "[60]\tvalid_0's l2: 0.0127185\n",
      "[61]\tvalid_0's l2: 0.0127206\n",
      "[62]\tvalid_0's l2: 0.0127255\n",
      "[63]\tvalid_0's l2: 0.0127303\n",
      "[64]\tvalid_0's l2: 0.0127294\n",
      "[65]\tvalid_0's l2: 0.0127362\n",
      "[66]\tvalid_0's l2: 0.0127332\n",
      "[67]\tvalid_0's l2: 0.012737\n",
      "[68]\tvalid_0's l2: 0.0127377\n",
      "[69]\tvalid_0's l2: 0.0127402\n",
      "[70]\tvalid_0's l2: 0.0127476\n",
      "[71]\tvalid_0's l2: 0.0127504\n",
      "[72]\tvalid_0's l2: 0.0127581\n",
      "[73]\tvalid_0's l2: 0.0127634\n",
      "[74]\tvalid_0's l2: 0.0127648\n",
      "[75]\tvalid_0's l2: 0.0127615\n",
      "[76]\tvalid_0's l2: 0.0127698\n",
      "[77]\tvalid_0's l2: 0.0127708\n",
      "[78]\tvalid_0's l2: 0.0127762\n",
      "[79]\tvalid_0's l2: 0.0127759\n",
      "[80]\tvalid_0's l2: 0.0127783\n",
      "[81]\tvalid_0's l2: 0.0127815\n",
      "[82]\tvalid_0's l2: 0.0127849\n",
      "[83]\tvalid_0's l2: 0.0127899\n",
      "[84]\tvalid_0's l2: 0.0127943\n",
      "[85]\tvalid_0's l2: 0.0127963\n",
      "[86]\tvalid_0's l2: 0.0128003\n",
      "[87]\tvalid_0's l2: 0.0128035\n",
      "[88]\tvalid_0's l2: 0.0128035\n",
      "[89]\tvalid_0's l2: 0.0128051\n",
      "[90]\tvalid_0's l2: 0.012811\n",
      "[91]\tvalid_0's l2: 0.0128169\n",
      "[92]\tvalid_0's l2: 0.0128198\n",
      "[93]\tvalid_0's l2: 0.0128233\n",
      "[94]\tvalid_0's l2: 0.0128229\n",
      "[95]\tvalid_0's l2: 0.0128214\n",
      "[96]\tvalid_0's l2: 0.0128243\n",
      "[97]\tvalid_0's l2: 0.0128251\n",
      "[98]\tvalid_0's l2: 0.0128303\n",
      "[99]\tvalid_0's l2: 0.012834\n",
      "[100]\tvalid_0's l2: 0.0128406\n",
      "[101]\tvalid_0's l2: 0.0128444\n",
      "[102]\tvalid_0's l2: 0.0128501\n",
      "[103]\tvalid_0's l2: 0.0128495\n",
      "[104]\tvalid_0's l2: 0.0128479\n",
      "[105]\tvalid_0's l2: 0.012851\n",
      "[106]\tvalid_0's l2: 0.0128512\n",
      "[107]\tvalid_0's l2: 0.0128585\n",
      "[108]\tvalid_0's l2: 0.0128591\n",
      "[109]\tvalid_0's l2: 0.0128658\n",
      "[110]\tvalid_0's l2: 0.0128685\n",
      "[111]\tvalid_0's l2: 0.0128726\n",
      "[112]\tvalid_0's l2: 0.0128757\n",
      "[113]\tvalid_0's l2: 0.012874\n",
      "[114]\tvalid_0's l2: 0.0128777\n",
      "[115]\tvalid_0's l2: 0.0128794\n",
      "[116]\tvalid_0's l2: 0.0128837\n",
      "[117]\tvalid_0's l2: 0.0128817\n",
      "[118]\tvalid_0's l2: 0.0128815\n",
      "[119]\tvalid_0's l2: 0.0128834\n",
      "[120]\tvalid_0's l2: 0.0128812\n",
      "[121]\tvalid_0's l2: 0.0128885\n",
      "[122]\tvalid_0's l2: 0.0128907\n",
      "[123]\tvalid_0's l2: 0.0128935\n",
      "[124]\tvalid_0's l2: 0.0129004\n",
      "[125]\tvalid_0's l2: 0.0129011\n",
      "[126]\tvalid_0's l2: 0.0128985\n",
      "[127]\tvalid_0's l2: 0.0129002\n",
      "[128]\tvalid_0's l2: 0.012905\n",
      "[129]\tvalid_0's l2: 0.0129078\n",
      "[130]\tvalid_0's l2: 0.0129135\n",
      "[131]\tvalid_0's l2: 0.0129179\n",
      "[132]\tvalid_0's l2: 0.01292\n",
      "[133]\tvalid_0's l2: 0.012923\n",
      "[134]\tvalid_0's l2: 0.012926\n",
      "[135]\tvalid_0's l2: 0.0129339\n",
      "[136]\tvalid_0's l2: 0.0129361\n",
      "[137]\tvalid_0's l2: 0.0129354\n",
      "[138]\tvalid_0's l2: 0.0129368\n",
      "[139]\tvalid_0's l2: 0.0129435\n",
      "[140]\tvalid_0's l2: 0.0129475\n",
      "[141]\tvalid_0's l2: 0.0129491\n",
      "[142]\tvalid_0's l2: 0.0129519\n",
      "[143]\tvalid_0's l2: 0.0129524\n",
      "[144]\tvalid_0's l2: 0.0129546\n",
      "[145]\tvalid_0's l2: 0.0129548\n",
      "[146]\tvalid_0's l2: 0.0129587\n",
      "[147]\tvalid_0's l2: 0.0129624\n",
      "[148]\tvalid_0's l2: 0.0129646\n",
      "[149]\tvalid_0's l2: 0.0129652\n",
      "[150]\tvalid_0's l2: 0.012962\n",
      "[151]\tvalid_0's l2: 0.0129591\n",
      "[152]\tvalid_0's l2: 0.0129612\n",
      "[153]\tvalid_0's l2: 0.0129657\n",
      "[154]\tvalid_0's l2: 0.0129675\n",
      "[155]\tvalid_0's l2: 0.0129691\n",
      "[156]\tvalid_0's l2: 0.0129756\n",
      "[157]\tvalid_0's l2: 0.0129823\n",
      "[158]\tvalid_0's l2: 0.0129852\n",
      "[159]\tvalid_0's l2: 0.0129896\n",
      "[160]\tvalid_0's l2: 0.0129937\n",
      "[161]\tvalid_0's l2: 0.0129964\n",
      "[162]\tvalid_0's l2: 0.0129949\n",
      "[163]\tvalid_0's l2: 0.0129909\n",
      "[164]\tvalid_0's l2: 0.0129894\n",
      "[165]\tvalid_0's l2: 0.0129928\n",
      "[166]\tvalid_0's l2: 0.0129932\n",
      "[167]\tvalid_0's l2: 0.0129964\n",
      "[168]\tvalid_0's l2: 0.0129957\n",
      "[169]\tvalid_0's l2: 0.0130026\n",
      "[170]\tvalid_0's l2: 0.0130007\n",
      "[171]\tvalid_0's l2: 0.0130059\n",
      "[172]\tvalid_0's l2: 0.0130064\n",
      "[173]\tvalid_0's l2: 0.0130083\n",
      "[174]\tvalid_0's l2: 0.0130115\n",
      "[175]\tvalid_0's l2: 0.0130115\n",
      "[176]\tvalid_0's l2: 0.0130107\n",
      "[177]\tvalid_0's l2: 0.0130157\n",
      "[178]\tvalid_0's l2: 0.0130207\n",
      "[179]\tvalid_0's l2: 0.0130195\n",
      "[180]\tvalid_0's l2: 0.0130224\n",
      "[181]\tvalid_0's l2: 0.0130262\n",
      "[182]\tvalid_0's l2: 0.0130288\n",
      "[183]\tvalid_0's l2: 0.0130331\n",
      "[184]\tvalid_0's l2: 0.0130347\n",
      "[185]\tvalid_0's l2: 0.0130341\n",
      "[186]\tvalid_0's l2: 0.0130363\n",
      "[187]\tvalid_0's l2: 0.0130383\n",
      "[188]\tvalid_0's l2: 0.0130382\n",
      "[189]\tvalid_0's l2: 0.0130432\n",
      "[190]\tvalid_0's l2: 0.0130431\n",
      "[191]\tvalid_0's l2: 0.0130404\n",
      "[192]\tvalid_0's l2: 0.0130458\n",
      "[193]\tvalid_0's l2: 0.0130441\n",
      "[194]\tvalid_0's l2: 0.0130437\n",
      "[195]\tvalid_0's l2: 0.0130438\n",
      "[196]\tvalid_0's l2: 0.0130474\n",
      "[197]\tvalid_0's l2: 0.0130514\n",
      "[198]\tvalid_0's l2: 0.0130577\n",
      "[199]\tvalid_0's l2: 0.0130576\n",
      "[200]\tvalid_0's l2: 0.0130602\n",
      "[201]\tvalid_0's l2: 0.0130622\n",
      "[202]\tvalid_0's l2: 0.013063\n",
      "[203]\tvalid_0's l2: 0.0130608\n",
      "[204]\tvalid_0's l2: 0.0130604\n",
      "[205]\tvalid_0's l2: 0.0130602\n",
      "[206]\tvalid_0's l2: 0.0130629\n",
      "[207]\tvalid_0's l2: 0.0130639\n",
      "[208]\tvalid_0's l2: 0.013061\n",
      "[209]\tvalid_0's l2: 0.0130597\n",
      "[210]\tvalid_0's l2: 0.0130594\n",
      "[211]\tvalid_0's l2: 0.0130576\n",
      "[212]\tvalid_0's l2: 0.0130563\n",
      "[213]\tvalid_0's l2: 0.0130545\n",
      "[214]\tvalid_0's l2: 0.0130578\n",
      "[215]\tvalid_0's l2: 0.0130586\n",
      "[216]\tvalid_0's l2: 0.0130541\n",
      "[217]\tvalid_0's l2: 0.0130542\n",
      "[218]\tvalid_0's l2: 0.0130532\n",
      "[219]\tvalid_0's l2: 0.0130479\n",
      "[220]\tvalid_0's l2: 0.0130471\n",
      "[221]\tvalid_0's l2: 0.0130442\n",
      "[222]\tvalid_0's l2: 0.0130442\n",
      "[223]\tvalid_0's l2: 0.0130424\n",
      "[224]\tvalid_0's l2: 0.0130429\n",
      "[225]\tvalid_0's l2: 0.0130404\n",
      "[226]\tvalid_0's l2: 0.0130393\n",
      "[227]\tvalid_0's l2: 0.0130415\n",
      "[228]\tvalid_0's l2: 0.0130428\n",
      "[229]\tvalid_0's l2: 0.0130427\n",
      "[230]\tvalid_0's l2: 0.0130423\n",
      "[231]\tvalid_0's l2: 0.0130423\n",
      "[232]\tvalid_0's l2: 0.0130428\n",
      "[233]\tvalid_0's l2: 0.0130417\n",
      "[234]\tvalid_0's l2: 0.0130445\n",
      "[235]\tvalid_0's l2: 0.0130515\n",
      "[236]\tvalid_0's l2: 0.0130527\n",
      "[237]\tvalid_0's l2: 0.0130534\n",
      "[238]\tvalid_0's l2: 0.0130561\n",
      "[239]\tvalid_0's l2: 0.0130598\n",
      "[240]\tvalid_0's l2: 0.0130623\n",
      "[241]\tvalid_0's l2: 0.0130621\n",
      "[242]\tvalid_0's l2: 0.0130579\n",
      "[243]\tvalid_0's l2: 0.0130575\n",
      "[244]\tvalid_0's l2: 0.0130535\n",
      "[245]\tvalid_0's l2: 0.0130516\n",
      "[246]\tvalid_0's l2: 0.0130449\n",
      "[247]\tvalid_0's l2: 0.0130431\n",
      "[248]\tvalid_0's l2: 0.0130395\n",
      "[249]\tvalid_0's l2: 0.0130355\n",
      "[250]\tvalid_0's l2: 0.0130351\n",
      "[251]\tvalid_0's l2: 0.0130322\n",
      "[252]\tvalid_0's l2: 0.0130312\n",
      "[253]\tvalid_0's l2: 0.0130313\n",
      "[254]\tvalid_0's l2: 0.0130313\n",
      "[255]\tvalid_0's l2: 0.0130331\n",
      "[256]\tvalid_0's l2: 0.013037\n",
      "[257]\tvalid_0's l2: 0.0130396\n",
      "[258]\tvalid_0's l2: 0.0130386\n",
      "[259]\tvalid_0's l2: 0.0130416\n",
      "[260]\tvalid_0's l2: 0.0130404\n",
      "[261]\tvalid_0's l2: 0.0130412\n",
      "[262]\tvalid_0's l2: 0.0130374\n",
      "[263]\tvalid_0's l2: 0.0130384\n",
      "[264]\tvalid_0's l2: 0.0130419\n",
      "[265]\tvalid_0's l2: 0.0130404\n",
      "[266]\tvalid_0's l2: 0.0130429\n",
      "[267]\tvalid_0's l2: 0.0130449\n",
      "[268]\tvalid_0's l2: 0.0130473\n",
      "[269]\tvalid_0's l2: 0.0130454\n",
      "[270]\tvalid_0's l2: 0.013046\n",
      "[271]\tvalid_0's l2: 0.0130484\n",
      "[272]\tvalid_0's l2: 0.0130493\n",
      "[273]\tvalid_0's l2: 0.0130514\n",
      "[274]\tvalid_0's l2: 0.013052\n",
      "[275]\tvalid_0's l2: 0.0130511\n",
      "[276]\tvalid_0's l2: 0.013051\n",
      "[277]\tvalid_0's l2: 0.0130521\n",
      "[278]\tvalid_0's l2: 0.0130507\n",
      "[279]\tvalid_0's l2: 0.0130518\n",
      "[280]\tvalid_0's l2: 0.0130483\n",
      "[281]\tvalid_0's l2: 0.0130462\n",
      "[282]\tvalid_0's l2: 0.0130422\n",
      "[283]\tvalid_0's l2: 0.0130443\n",
      "[284]\tvalid_0's l2: 0.0130463\n",
      "[285]\tvalid_0's l2: 0.0130451\n",
      "[286]\tvalid_0's l2: 0.0130483\n",
      "[287]\tvalid_0's l2: 0.0130529\n",
      "[288]\tvalid_0's l2: 0.013057\n",
      "[289]\tvalid_0's l2: 0.0130604\n",
      "[290]\tvalid_0's l2: 0.0130623\n",
      "[291]\tvalid_0's l2: 0.0130583\n",
      "[292]\tvalid_0's l2: 0.0130579\n",
      "[293]\tvalid_0's l2: 0.0130611\n",
      "[294]\tvalid_0's l2: 0.0130643\n",
      "[295]\tvalid_0's l2: 0.0130678\n",
      "[296]\tvalid_0's l2: 0.0130701\n",
      "[297]\tvalid_0's l2: 0.0130697\n",
      "[298]\tvalid_0's l2: 0.0130686\n",
      "[299]\tvalid_0's l2: 0.0130672\n",
      "[300]\tvalid_0's l2: 0.0130663\n",
      "[301]\tvalid_0's l2: 0.013065\n",
      "[302]\tvalid_0's l2: 0.0130633\n",
      "[303]\tvalid_0's l2: 0.0130623\n",
      "[304]\tvalid_0's l2: 0.0130609\n",
      "[305]\tvalid_0's l2: 0.0130635\n",
      "[306]\tvalid_0's l2: 0.0130656\n",
      "[307]\tvalid_0's l2: 0.0130673\n",
      "[308]\tvalid_0's l2: 0.0130689\n",
      "[309]\tvalid_0's l2: 0.0130673\n",
      "[310]\tvalid_0's l2: 0.0130721\n",
      "[311]\tvalid_0's l2: 0.0130711\n",
      "[312]\tvalid_0's l2: 0.0130745\n",
      "[313]\tvalid_0's l2: 0.0130755\n",
      "[314]\tvalid_0's l2: 0.0130777\n",
      "[315]\tvalid_0's l2: 0.0130789\n",
      "[316]\tvalid_0's l2: 0.0130817\n",
      "[317]\tvalid_0's l2: 0.0130854\n",
      "[318]\tvalid_0's l2: 0.0130891\n",
      "[319]\tvalid_0's l2: 0.0130895\n",
      "[320]\tvalid_0's l2: 0.0130907\n",
      "[321]\tvalid_0's l2: 0.0130904\n",
      "[322]\tvalid_0's l2: 0.0130857\n",
      "[323]\tvalid_0's l2: 0.0130823\n",
      "[324]\tvalid_0's l2: 0.0130794\n",
      "[325]\tvalid_0's l2: 0.0130809\n",
      "[326]\tvalid_0's l2: 0.0130809\n",
      "[327]\tvalid_0's l2: 0.0130779\n",
      "[328]\tvalid_0's l2: 0.0130772\n",
      "[329]\tvalid_0's l2: 0.0130719\n",
      "[330]\tvalid_0's l2: 0.0130669\n",
      "[331]\tvalid_0's l2: 0.0130667\n",
      "[332]\tvalid_0's l2: 0.0130627\n",
      "[333]\tvalid_0's l2: 0.0130591\n",
      "[334]\tvalid_0's l2: 0.0130574\n",
      "[335]\tvalid_0's l2: 0.0130576\n",
      "[336]\tvalid_0's l2: 0.0130575\n",
      "[337]\tvalid_0's l2: 0.0130558\n",
      "[338]\tvalid_0's l2: 0.0130501\n",
      "[339]\tvalid_0's l2: 0.013044\n",
      "[340]\tvalid_0's l2: 0.0130457\n",
      "[341]\tvalid_0's l2: 0.013047\n",
      "[342]\tvalid_0's l2: 0.0130481\n",
      "[343]\tvalid_0's l2: 0.0130516\n",
      "[344]\tvalid_0's l2: 0.0130546\n",
      "[345]\tvalid_0's l2: 0.0130545\n",
      "[346]\tvalid_0's l2: 0.0130526\n",
      "[347]\tvalid_0's l2: 0.0130538\n",
      "[348]\tvalid_0's l2: 0.0130509\n",
      "[349]\tvalid_0's l2: 0.0130532\n",
      "[350]\tvalid_0's l2: 0.0130552\n",
      "[351]\tvalid_0's l2: 0.013057\n",
      "[352]\tvalid_0's l2: 0.0130564\n",
      "[353]\tvalid_0's l2: 0.0130574\n",
      "[354]\tvalid_0's l2: 0.0130536\n",
      "[355]\tvalid_0's l2: 0.0130525\n",
      "[356]\tvalid_0's l2: 0.0130546\n",
      "[357]\tvalid_0's l2: 0.0130542\n",
      "[358]\tvalid_0's l2: 0.0130529\n",
      "[359]\tvalid_0's l2: 0.0130499\n",
      "[360]\tvalid_0's l2: 0.0130456\n",
      "[361]\tvalid_0's l2: 0.0130437\n",
      "[362]\tvalid_0's l2: 0.0130439\n",
      "[363]\tvalid_0's l2: 0.0130432\n",
      "[364]\tvalid_0's l2: 0.0130418\n",
      "[365]\tvalid_0's l2: 0.0130438\n",
      "[366]\tvalid_0's l2: 0.0130441\n",
      "[367]\tvalid_0's l2: 0.0130476\n",
      "[368]\tvalid_0's l2: 0.0130486\n",
      "[369]\tvalid_0's l2: 0.0130506\n",
      "[370]\tvalid_0's l2: 0.0130533\n",
      "[371]\tvalid_0's l2: 0.0130564\n",
      "[372]\tvalid_0's l2: 0.0130521\n",
      "[373]\tvalid_0's l2: 0.0130499\n",
      "[374]\tvalid_0's l2: 0.0130479\n",
      "[375]\tvalid_0's l2: 0.0130435\n",
      "[376]\tvalid_0's l2: 0.0130429\n",
      "[377]\tvalid_0's l2: 0.0130435\n",
      "[378]\tvalid_0's l2: 0.0130434\n",
      "[379]\tvalid_0's l2: 0.0130421\n",
      "[380]\tvalid_0's l2: 0.0130366\n",
      "[381]\tvalid_0's l2: 0.013037\n",
      "[382]\tvalid_0's l2: 0.013037\n",
      "[383]\tvalid_0's l2: 0.0130359\n",
      "[384]\tvalid_0's l2: 0.0130325\n",
      "[385]\tvalid_0's l2: 0.0130331\n",
      "[386]\tvalid_0's l2: 0.0130328\n",
      "[387]\tvalid_0's l2: 0.0130319\n",
      "[388]\tvalid_0's l2: 0.0130308\n",
      "[389]\tvalid_0's l2: 0.0130276\n",
      "[390]\tvalid_0's l2: 0.0130244\n",
      "[391]\tvalid_0's l2: 0.0130221\n",
      "[392]\tvalid_0's l2: 0.0130179\n",
      "[393]\tvalid_0's l2: 0.0130167\n",
      "[394]\tvalid_0's l2: 0.0130153\n",
      "[395]\tvalid_0's l2: 0.0130134\n",
      "[396]\tvalid_0's l2: 0.0130117\n",
      "[397]\tvalid_0's l2: 0.013016\n",
      "[398]\tvalid_0's l2: 0.0130154\n",
      "[399]\tvalid_0's l2: 0.013016\n",
      "[400]\tvalid_0's l2: 0.0130159\n",
      "[401]\tvalid_0's l2: 0.0130198\n",
      "[402]\tvalid_0's l2: 0.0130217\n",
      "[403]\tvalid_0's l2: 0.0130248\n",
      "[404]\tvalid_0's l2: 0.0130248\n",
      "[405]\tvalid_0's l2: 0.0130256\n",
      "[406]\tvalid_0's l2: 0.0130282\n",
      "[407]\tvalid_0's l2: 0.0130326\n",
      "[408]\tvalid_0's l2: 0.0130286\n",
      "[409]\tvalid_0's l2: 0.0130324\n",
      "[410]\tvalid_0's l2: 0.0130319\n",
      "[411]\tvalid_0's l2: 0.0130326\n",
      "[412]\tvalid_0's l2: 0.0130369\n",
      "[413]\tvalid_0's l2: 0.0130398\n",
      "[414]\tvalid_0's l2: 0.0130418\n",
      "[415]\tvalid_0's l2: 0.0130428\n",
      "[416]\tvalid_0's l2: 0.0130443\n",
      "[417]\tvalid_0's l2: 0.0130453\n",
      "[418]\tvalid_0's l2: 0.0130471\n",
      "[419]\tvalid_0's l2: 0.0130464\n",
      "[420]\tvalid_0's l2: 0.0130515\n",
      "[421]\tvalid_0's l2: 0.0130528\n",
      "[422]\tvalid_0's l2: 0.0130585\n",
      "[423]\tvalid_0's l2: 0.0130585\n",
      "[424]\tvalid_0's l2: 0.0130578\n",
      "[425]\tvalid_0's l2: 0.013063\n",
      "[426]\tvalid_0's l2: 0.0130652\n",
      "[427]\tvalid_0's l2: 0.0130653\n",
      "[428]\tvalid_0's l2: 0.0130683\n",
      "[429]\tvalid_0's l2: 0.0130681\n",
      "[430]\tvalid_0's l2: 0.0130687\n",
      "[431]\tvalid_0's l2: 0.0130704\n",
      "[432]\tvalid_0's l2: 0.0130735\n",
      "[433]\tvalid_0's l2: 0.0130741\n",
      "[434]\tvalid_0's l2: 0.0130782\n",
      "[435]\tvalid_0's l2: 0.0130783\n",
      "[436]\tvalid_0's l2: 0.01308\n",
      "[437]\tvalid_0's l2: 0.0130833\n",
      "[438]\tvalid_0's l2: 0.0130821\n",
      "[439]\tvalid_0's l2: 0.0130847\n",
      "[440]\tvalid_0's l2: 0.0130832\n",
      "[441]\tvalid_0's l2: 0.0130849\n",
      "[442]\tvalid_0's l2: 0.0130844\n",
      "[443]\tvalid_0's l2: 0.0130823\n",
      "[444]\tvalid_0's l2: 0.0130798\n",
      "[445]\tvalid_0's l2: 0.0130797\n",
      "[446]\tvalid_0's l2: 0.013079\n",
      "[447]\tvalid_0's l2: 0.0130813\n",
      "[448]\tvalid_0's l2: 0.0130836\n",
      "[449]\tvalid_0's l2: 0.0130817\n",
      "[450]\tvalid_0's l2: 0.01308\n",
      "[451]\tvalid_0's l2: 0.0130797\n",
      "[452]\tvalid_0's l2: 0.0130768\n",
      "[453]\tvalid_0's l2: 0.0130809\n",
      "[454]\tvalid_0's l2: 0.013076\n",
      "[455]\tvalid_0's l2: 0.0130764\n",
      "[456]\tvalid_0's l2: 0.0130759\n",
      "[457]\tvalid_0's l2: 0.0130757\n",
      "[458]\tvalid_0's l2: 0.0130784\n",
      "[459]\tvalid_0's l2: 0.0130795\n",
      "[460]\tvalid_0's l2: 0.0130776\n",
      "[461]\tvalid_0's l2: 0.0130751\n",
      "[462]\tvalid_0's l2: 0.0130769\n",
      "[463]\tvalid_0's l2: 0.0130791\n",
      "[464]\tvalid_0's l2: 0.0130802\n",
      "[465]\tvalid_0's l2: 0.0130835\n",
      "[466]\tvalid_0's l2: 0.0130822\n",
      "[467]\tvalid_0's l2: 0.0130783\n",
      "[468]\tvalid_0's l2: 0.0130781\n",
      "[469]\tvalid_0's l2: 0.0130789\n",
      "[470]\tvalid_0's l2: 0.0130779\n"
     ]
    }
   ],
   "source": [
    "x_train = df_train.drop(['parcelid', \n",
    "               'logerror', \n",
    "               'transactiondate', \n",
    "               'propertyzoningdesc', \n",
    "               'propertycountylandusecode',\n",
    "               'basementsqft',\n",
    "               'buildingclasstypeid',\n",
    "               'finishedsquarefeet13',\n",
    "               'storytypeid',\n",
    "               'assessmentyear'], axis=1,inplace = False)\n",
    "y_train = df_train['logerror'].values\n",
    "print(x_train.shape, y_train.shape)\n",
    "\n",
    "train_columns = x_train.columns\n",
    "\n",
    "for c in x_train.dtypes[x_train.dtypes == object].index.values:\n",
    "    x_train[c] = (x_train[c] == True)\n",
    "\n",
    "# del df_train; gc.collect()\n",
    "\n",
    "split = 90000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "x_train = x_train.values.astype(np.float32, copy=False)\n",
    "x_valid = x_valid.values.astype(np.float32, copy=False)\n",
    "\n",
    "d_train = lgb.Dataset(x_train, label=y_train)\n",
    "d_valid = lgb.Dataset(x_valid, label=y_valid)\n",
    "params = {}\n",
    "params['max_bin'] = 10\n",
    "params['learning_rate'] = 0.012\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'l2'\n",
    "params['sub_feature'] = 0.8\n",
    "params['bagging_fraction'] = 0.85 # sub_row\n",
    "params['bagging_freq'] = 40\n",
    "params['num_leaves'] = 256\n",
    "params['min_data'] = 500\n",
    "params['min_hessian'] = 0.05\n",
    "\n",
    "watchlist = [d_valid]\n",
    "clf = lgb.train(params, d_train, 470, watchlist)\n",
    "\n",
    "# del d_train, d_valid; gc.collect()\n",
    "# del x_train, x_valid; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start write result ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e8d702cc6513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start write result ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/sample_submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Start write result ...\")\n",
    "sub = pd.read_csv('../../data/sample_submission.csv')\n",
    "\n",
    "import pandas ad \n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "CalibrationFactor = 0.03\n",
    "cal = CalibrationFactor * 0.013\n",
    "\n",
    "for d in l_test_transdate:\n",
    "    l_test_columns = ['lastgap%s' % d if (c == 'lastgap') else c for c in train_columns]\n",
    "    x_test = df_test[l_test_columns]\n",
    "    for c in x_test.dtypes[x_test.dtypes == object].index.values:\n",
    "        x_test[c] = (x_test[c] == True)\n",
    "    x_test = x_test.values.astype(np.float32, copy=False)\n",
    "\n",
    "    print(\"Start prediction ...\")\n",
    "    # num_threads > 1 will predict very slow in kernal\n",
    "    model.reset_parameter({\"num_threads\":4})\n",
    "    #sub[d] = (1 - CalibrationFactor) * clf.predict(x_test) + cal\n",
    "    sub[d] = model.predict(x_test)\n",
    "    \n",
    "    sub.to_csv('lgb_starter.csv', index=False, float_format='%.4f')\n",
    "    del x_test; gc.collect()\n",
    "    print('%s done.' % d)\n",
    "end = time.time()\n",
    "print('time elapsed %ds' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
