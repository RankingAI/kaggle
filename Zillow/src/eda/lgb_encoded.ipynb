{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '/Users/yuanpingzhou/project/workspace/python/kaggle/Zillow/data/p1/train.hdf'\n",
    "df_train = pd.read_hdf(path_or_buf= file_path,key = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# missing_df = df_train.isnull().sum(axis=0).reset_index()\n",
    "# missing_df.columns = ['column_name', 'missing_count']\n",
    "# missing_df[missing_df['missing_count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parcelid int64\n",
      "logerror float64\n",
      "lastgap float64\n",
      "monthyear int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "int8       1604\n",
       "float32      32\n",
       "int32         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col,dt in zip(df_train.columns,df_train.dtypes):\n",
    "    if(dt == np.float64):\n",
    "        print(col,dt)\n",
    "        df_train[col] = df_train[col].astype(np.float32)\n",
    "    elif(dt == np.int64):\n",
    "        print(col,dt)\n",
    "        df_train[col] = df_train[col].astype(np.int32)\n",
    "df_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90275\n",
      "88431\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "df_train = df_train[(df_train['logerror'] > -0.4) & (df_train['logerror'] < 0.4)]\n",
    "print(len(df_train))\n",
    "\n",
    "x_train = df_train.drop(['logerror','parcelid'],axis= 1)\n",
    "y_train = df_train['logerror']\n",
    "l_train_columns = x_train.columns\n",
    "\n",
    "split = 80000\n",
    "x_train, y_train, x_valid, y_valid = x_train[:split], y_train[:split], x_train[split:], y_train[split:]\n",
    "x_train = x_train.values.astype(np.float32, copy=False)\n",
    "x_valid = x_valid.values.astype(np.float32, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import lightgbm\n",
    "\n",
    "d_train = lightgbm.Dataset(x_train, label=y_train)\n",
    "d_valid = lightgbm.Dataset(x_valid, label=y_valid)\n",
    "\n",
    "params = {}\n",
    "params['max_bin'] = 8\n",
    "params['boosting_type'] = 'gbdt'\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = 'mae'\n",
    "params['sub_feature'] = 0.8\n",
    "params['bagging_fraction'] = 0.85  # sub_row\n",
    "params['num_leaves'] = 128\n",
    "params['min_data'] = 300\n",
    "params['min_hessian'] = 0.01\n",
    "\n",
    "#l_learning_rate = [0.001*math.pow(2.0,i) for i in range(7)]\n",
    "l_learning_rate = [0.018 + 0.002*i for i in range(5)]\n",
    "l_bagging_freq = [20+i*10 for i in range(5)]\n",
    "# l_learning_rate = [0.01]\n",
    "# l_bagging_freq = [40]\n",
    "        \n",
    "# BestParams = {'learning_rate':0.0,'bagging_freq':0}\n",
    "# BestMAE = 1.0\n",
    "# for lr in l_learning_rate:\n",
    "#     for bf in l_bagging_freq:\n",
    "#         params['learning_rate'] = lr\n",
    "#         params['bagging_freq'] = bf\n",
    "        \n",
    "#         model = lightgbm.cv(params, d_train, 100, nfold=5,verbose_eval= True)\n",
    "#         if(model.get('l1-mean')[-1] < BestMAE):\n",
    "#             BestMAE = model.get('l1-mean')[-1]\n",
    "#             BestParams['learning_rate'] = lr\n",
    "#             BestParams['bagging_freq'] = bf\n",
    "# print(BestParams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "params['learning_rate'] = 0.02\n",
    "params['bagging_freq'] = 30\n",
    "x_train = df_train.drop(['logerror','parcelid'],axis= 1)\n",
    "y_train = df_train['logerror']\n",
    "d_train = lightgbm.Dataset(x_train, label=y_train)\n",
    "model = lightgbm.train(params,d_train,100,verbose_eval= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = '/Users/yuanpingzhou/project/workspace/python/kaggle/Zillow/data/p1/test.hdf'\n",
    "df_test = pd.read_hdf(path_or_buf= file_path,key = 'test')\n",
    "sub = pd.DataFrame(index = df_test.index)\n",
    "sub['ParcelId'] = df_test['parcelid']\n",
    "\n",
    "# df_test.drop(l_test_transdate,axis = 1,inplace=True)\n",
    "# df_test.drop('parcelid',axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prediction ...\n",
      "0.0134480309018\n",
      "0.013446911263\n",
      "0.0134523743616\n",
      "0.0134417438461\n",
      "0.013470370291\n",
      "0.0134561359555\n",
      "0.0134484411045\n",
      "0.0134581279229\n",
      "0.0134458168905\n",
      "0.0134590822073\n",
      "0.0134812310434\n",
      "0.0134442905426\n",
      "0.0134446496209\n",
      "0.0134536666461\n",
      "0.0134716707567\n",
      "201610 done. time elapsed 152s\n",
      "Start prediction ...\n",
      "0.0135621312283\n",
      "0.0135625854368\n",
      "0.0135678780184\n",
      "0.0135567867748\n",
      "0.0135852429481\n",
      "0.013571600723\n",
      "0.0135637050965\n",
      "0.0135738054457\n",
      "0.0135615245209\n",
      "0.0135744162027\n",
      "0.0135970168175\n",
      "0.0135599204942\n",
      "0.0135598993446\n",
      "0.0135686214633\n",
      "0.013587367122\n",
      "201611 done. time elapsed 157s\n",
      "Start prediction ...\n",
      "0.0135621312283\n",
      "0.0135625854368\n",
      "0.0135678780184\n",
      "0.0135567867748\n",
      "0.0135852429481\n",
      "0.013571600723\n",
      "0.0135637050965\n",
      "0.0135738054457\n",
      "0.0135615245209\n",
      "0.0135744162027\n",
      "0.0135970168175\n",
      "0.0135599204942\n",
      "0.0135598993446\n",
      "0.0135686214633\n",
      "0.013587367122\n",
      "201612 done. time elapsed 153s\n",
      "Start prediction ...\n",
      "0.013464057846\n",
      "0.0134608418982\n",
      "0.0134681916956\n",
      "0.0134565671125\n",
      "0.0134851496472\n",
      "0.0134700203051\n",
      "0.0134632809674\n",
      "0.0134736213302\n",
      "0.0134609264802\n",
      "0.0134738077737\n",
      "0.0134959817737\n",
      "0.0134588800549\n",
      "0.0134589007039\n",
      "0.0134684471733\n",
      "0.0134865245845\n",
      "201710 done. time elapsed 143s\n",
      "Start prediction ...\n",
      "0.0135772800172\n",
      "0.0135756131976\n",
      "0.0135828035693\n",
      "0.0135706690142\n",
      "0.0135991707464\n",
      "0.0135845093295\n",
      "0.0135776089129\n",
      "0.013588340812\n",
      "0.0135756922973\n",
      "0.0135883033943\n",
      "0.0136107833321\n",
      "0.013573673648\n",
      "0.0135733040681\n",
      "0.0135824653296\n",
      "0.013601352671\n",
      "201711 done. time elapsed 142s\n",
      "Start prediction ...\n",
      "0.0135772800172\n",
      "0.0135756131976\n",
      "0.0135828035693\n",
      "0.0135706690142\n",
      "0.0135991707464\n",
      "0.0135845093295\n",
      "0.0135776089129\n",
      "0.013588340812\n",
      "0.0135756922973\n",
      "0.0135883033943\n",
      "0.0136107833321\n",
      "0.013573673648\n",
      "0.0135733040681\n",
      "0.0135824653296\n",
      "0.013601352671\n",
      "201712 done. time elapsed 139s\n",
      "time elapsed 888s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "N = 200000\n",
    "l_test_transdate = ['201610', '201611', '201612', '201710', '201711', '201712']\n",
    "start = time.time()\n",
    "for d in l_test_transdate:\n",
    "    s0 = time.time()\n",
    "    print(\"Start prediction ...\")\n",
    "    \n",
    "    l_test_columns = ['%s%s' % (c,d) if (c in ['lastgap','monthyear','buildingage']) else c for c in l_train_columns]\n",
    "    x_test = df_test[l_test_columns]\n",
    "    for idx in range(0,len(x_test),N):\n",
    "        x_test_block = x_test[idx:idx + N].values.astype(np.float32, copy=False)\n",
    "        model.reset_parameter({\"num_threads\":4})\n",
    "        ret = model.predict(x_test_block)\n",
    "        sub.loc[x_test[idx:idx + N].index,d] = ret\n",
    "        print(np.mean(np.abs(ret)))\n",
    "\n",
    "    e0 = time.time()\n",
    "    print('%s done. time elapsed %ds' % (d,(e0 - s0)))\n",
    "end = time.time()\n",
    "sub.to_csv('lgb_starter.csv', index=False, float_format='%.4f')\n",
    "print('time elapsed %ds' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
