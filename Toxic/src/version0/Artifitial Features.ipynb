{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:52:52.930774Z",
     "start_time": "2018-01-18T14:52:52.852441Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill as pickle\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm as tqdm\n",
    "import os,sys,time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "class DataUtil2:\n",
    "    \"\"\"\"\"\"\n",
    "    @classmethod\n",
    "    def load(cls, file, format, date_cols= None):\n",
    "        \"\"\"\"\"\"\n",
    "        data = ''\n",
    "        if(format== 'csv'):\n",
    "            data = pd.read_csv(file, parse_dates= date_cols)\n",
    "        elif(format== 'json'):\n",
    "            with open(file, 'r') as i_file:\n",
    "                data = json.load(file)\n",
    "            i_file.close()\n",
    "        elif(format== 'pkl'):\n",
    "            with open(file, 'rb') as i_file:\n",
    "                data = pickle.load(i_file)\n",
    "            i_file.close()\n",
    "        elif(format == 'hdf'):\n",
    "            data = pd.read_hdf(path_or_buf= file, key='undefined')\n",
    "        elif(format == 'npz'):\n",
    "            data = scipy.sparse.load_npz(file)\n",
    "\n",
    "        return  data\n",
    "\n",
    "    @classmethod\n",
    "    def save(cls, data, file, format, precision= 8):\n",
    "        \"\"\"\"\"\"\n",
    "        if(format == 'csv'):\n",
    "            data.to_csv(file, float_format= '%%.%df' % precision, index= False)\n",
    "        elif(format == 'json'):\n",
    "            with open(file, 'w') as o_file:\n",
    "                json.dump(data, o_file, ensure_ascii= True, indent= 4)\n",
    "            o_file.close()\n",
    "        elif(format == 'pkl'):\n",
    "            with open(file, 'wb') as o_file:\n",
    "                pickle.dump(data, o_file, -1)\n",
    "            o_file.close()\n",
    "        elif(format== 'hdf'):\n",
    "            data.to_hdf(path_or_buf= file, key='undefined', mode='w', complib='blosc')\n",
    "        elif(format == 'npz'):\n",
    "            scipy.sparse.save_npz(file, data)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:53:21.892290Z",
     "start_time": "2018-01-18T14:52:52.932550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time elapsed 15.90625\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "iformat = 'csv'\n",
    "oformat = 'csv'\n",
    "DataBase = '../data'\n",
    "DataSet = {}\n",
    "start = time.time()\n",
    "for mod in ['train', 'test']:\n",
    "    DataSet[mod] = DataUtil2.load('%s/raw/%s.%s' % (DataBase, mod, iformat), oformat)\n",
    "    DataSet[mod]['comment_text'] = DataSet[mod]['comment_text'].fillna('nan')\n",
    "    DataSet[mod]['total_length'] = DataSet[mod]['comment_text'].apply(len)\n",
    "    DataSet[mod]['capitals'] = DataSet[mod]['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "    DataSet[mod]['caps_vs_length'] = DataSet[mod].apply(lambda row: float(row['capitals'])/float(row['total_length']),\n",
    "                                axis=1)\n",
    "    DataSet[mod]['num_exclamation_marks'] = DataSet[mod]['comment_text'].apply(lambda comment: comment.count('!'))\n",
    "    DataSet[mod]['num_question_marks'] = DataSet[mod]['comment_text'].apply(lambda comment: comment.count('?'))\n",
    "    DataSet[mod]['num_punctuation'] = DataSet[mod]['comment_text'].apply( lambda comment: sum(comment.count(w) for w in '.,;:'))\n",
    "    DataSet[mod]['imcomplete_punctuation'] = DataSet[mod]['comment_text'].apply( lambda comment: sum(comment.count(w) for w in '*,#,$'))    \n",
    "    DataSet[mod]['question_mask_ratio'] = DataSet[mod]['num_question_marks']/DataSet[mod]['total_length']\n",
    "    DataSet[mod]['exclamation_mark_ratio'] = DataSet[mod]['num_exclamation_marks']/DataSet[mod]['total_length']\n",
    "    DataSet[mod]['imcomplete_punctuation_ratio'] = DataSet[mod]['imcomplete_punctuation']/DataSet[mod]['total_length']\n",
    "    \n",
    "    DataSet[mod]['num_words'] = DataSet[mod]['comment_text'].apply(lambda comment: len(comment.split()))\n",
    "    DataSet[mod]['num_unique_words'] = DataSet[mod]['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    DataSet[mod]['words_vs_unique'] = DataSet[mod]['num_unique_words'] / DataSet[mod]['num_words']\n",
    "    DataSet[mod]['num_smilies'] = DataSet[mod]['comment_text'].apply(lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))\n",
    "    DataSet[mod]['similes_ratio'] = DataSet[mod]['num_smilies'] / DataSet[mod]['num_words']\n",
    "    \n",
    "    DataSet[mod].fillna(.0, inplace= True)\n",
    "end = time.time()\n",
    "print('time elapsed %s' % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-18T14:56:04.751213Z",
     "start_time": "2018-01-18T14:55:47.095756Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save fold 0 done.\n",
      "save fold 1 done.\n",
      "save fold 2 done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save test done.\n"
     ]
    }
   ],
   "source": [
    "label2binary = np.array([\n",
    "    [0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 1, 0],\n",
    "    [0, 0, 0, 0, 1, 1],\n",
    "    [0, 0, 0, 1, 0, 0],\n",
    "    [0, 0, 0, 1, 0, 1],\n",
    "    [0, 0, 0, 1, 1, 0],\n",
    "    [0, 0, 0, 1, 1, 1],\n",
    "    [0, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 0, 1],\n",
    "    [0, 0, 1, 0, 1, 0],\n",
    "    [0, 0, 1, 0, 1, 1],\n",
    "    [0, 0, 1, 1, 0, 0],\n",
    "    [0, 0, 1, 1, 0, 1],\n",
    "    [0, 0, 1, 1, 1, 0],\n",
    "    [0, 0, 1, 1, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 1],\n",
    "    [0, 1, 0, 0, 1, 0],\n",
    "    [0, 1, 0, 0, 1, 1],\n",
    "    [0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 1],\n",
    "    [0, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 1, 1],\n",
    "    [0, 1, 1, 0, 0, 0],\n",
    "    [0, 1, 1, 0, 0, 1],\n",
    "    [0, 1, 1, 0, 1, 0],\n",
    "    [0, 1, 1, 0, 1, 1],\n",
    "    [0, 1, 1, 1, 0, 0],\n",
    "    [0, 1, 1, 1, 0, 1],\n",
    "    [0, 1, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 1, 1],\n",
    "    [1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0, 1],\n",
    "    [1, 0, 0, 0, 1, 0],\n",
    "    [1, 0, 0, 0, 1, 1],\n",
    "    [1, 0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 1, 0, 1],\n",
    "    [1, 0, 0, 1, 1, 0],\n",
    "    [1, 0, 0, 1, 1, 1],\n",
    "    [1, 0, 1, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 0, 1],\n",
    "    [1, 0, 1, 0, 1, 0],\n",
    "    [1, 0, 1, 0, 1, 1],\n",
    "    [1, 0, 1, 1, 0, 0],\n",
    "    [1, 0, 1, 1, 0, 1],\n",
    "    [1, 0, 1, 1, 1, 0],\n",
    "    [1, 0, 1, 1, 1, 1],\n",
    "    [1, 1, 0, 0, 0, 0],\n",
    "    [1, 1, 0, 0, 0, 1],\n",
    "    [1, 1, 0, 0, 1, 0],\n",
    "    [1, 1, 0, 0, 1, 1],\n",
    "    [1, 1, 0, 1, 0, 0],\n",
    "    [1, 1, 0, 1, 0, 1],\n",
    "    [1, 1, 0, 1, 1, 0],\n",
    "    [1, 1, 0, 1, 1, 1],\n",
    "    [1, 1, 1, 0, 0, 0],\n",
    "    [1, 1, 1, 0, 0, 1],\n",
    "    [1, 1, 1, 0, 1, 0],\n",
    "    [1, 1, 1, 0, 1, 1],\n",
    "    [1, 1, 1, 1, 0, 0],\n",
    "    [1, 1, 1, 1, 0, 1],\n",
    "    [1, 1, 1, 1, 1, 0],\n",
    "    [1, 1, 1, 1, 1, 1],\n",
    "])\n",
    "\n",
    "colnames = ['total_length', 'capitals', 'caps_vs_length', 'num_exclamation_marks', 'num_question_marks', \n",
    "               'num_punctuation', 'imcomplete_punctuation', 'question_mask_ratio', 'exclamation_mark_ratio', \n",
    "               'imcomplete_punctuation_ratio', 'num_words', 'num_unique_words', 'words_vs_unique', 'num_smilies',\n",
    "               'similes_ratio']\n",
    "targets = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "OutputDir = '../data/meta/kfold/'\n",
    "strategy = 'artificial'\n",
    "kfold = 3\n",
    "\n",
    "def cv(X, y, l2b, n_splits=3):\n",
    "    def split(X, y):\n",
    "        return StratifiedKFold(n_splits=n_splits).split(X, y)\n",
    "    \n",
    "    def convert_y(y):\n",
    "        new_y = np.zeros([len(y)])\n",
    "        for i, val in enumerate(l2b):\n",
    "            idx = (y == val).max(axis=1)\n",
    "            new_y[idx] = i\n",
    "        return new_y\n",
    "    \n",
    "    fold = 0\n",
    "    for train, test in tqdm(split(X, convert_y(y.values)), total=n_splits):\n",
    "        FoldOutput = '%s/%s' % (OutputDir, fold)\n",
    "        if(os.path.exists(FoldOutput) == False):\n",
    "            os.makedirs(FoldOutput)\n",
    "        FoldOutputFile = '%s/valid_%s.csv' % (FoldOutput, strategy)\n",
    "        X_valid = X.loc[test,].copy()\n",
    "        y_valid = y.loc[test,].copy()\n",
    "        df = pd.DataFrame(index= range(len(X_valid)))\n",
    "        df[colnames] = X_valid\n",
    "        df[targets] = y_valid\n",
    "        DataUtil2.save(df, FoldOutputFile, 'csv', 4)\n",
    "        print('save fold %s done.' % fold)\n",
    "        fold += 1\n",
    "\n",
    "cv(DataSet['train'][colnames], DataSet['train'][targets], label2binary, kfold)\n",
    "\n",
    "#for fold in range(kfold):\n",
    "FoldOutput = '../data/meta/submit'\n",
    "if(os.path.exists(FoldOutput) == False):\n",
    "    os.makedirs(FoldOutput)\n",
    "FoldOutputFile = '%s/test_%s.csv' % (FoldOutput, strategy)\n",
    "OutputCols = ['id']\n",
    "OutputCols.extend(colnames)\n",
    "OutputCols.extend(targets)\n",
    "for t in targets:\n",
    "    DataSet['test'][t] = .0\n",
    "DataUtil2.save(DataSet['test'][OutputCols], FoldOutputFile, 'csv', 4)\n",
    "print('save test done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
