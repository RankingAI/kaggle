{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-31T15:26:23.862275Z",
     "start_time": "2017-12-31T15:26:23.777218Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "import scipy.sparse\n",
    "\n",
    "class DataUtil2:\n",
    "    \"\"\"\"\"\"\n",
    "    @classmethod\n",
    "    def load(cls, file, format, date_cols= None):\n",
    "        \"\"\"\"\"\"\n",
    "        data = ''\n",
    "        if(format== 'csv'):\n",
    "            data = pd.read_csv(file, parse_dates= date_cols)\n",
    "        elif(format== 'json'):\n",
    "            with open(file, 'r') as i_file:\n",
    "                data = json.load(file)\n",
    "            i_file.close()\n",
    "        elif(format== 'pkl'):\n",
    "            with open(file, 'rb') as i_file:\n",
    "                data = pickle.load(i_file)\n",
    "            i_file.close()\n",
    "        elif(format == 'hdf'):\n",
    "            data = pd.read_hdf(path_or_buf= file, key='undefined')\n",
    "#         elif(format == 'csr'):\n",
    "#             loader = np.load(file)\n",
    "#             data = csr_matrix((loader['data'], loader['indices'], loader['indptr']), shape=loader['shape'])\n",
    "        elif(format == 'npz'):\n",
    "            data = scipy.sparse.load_npz(file)\n",
    "\n",
    "        return  data\n",
    "\n",
    "    @classmethod\n",
    "    def save(cls, data, file, format, precision= 8):\n",
    "        \"\"\"\"\"\"\n",
    "        if(format == 'csv'):\n",
    "            data.to_csv(file, float_format= '%%.%df' % precision, index= False)\n",
    "        elif(format == 'json'):\n",
    "            with open(file, 'w') as o_file:\n",
    "                json.dump(data, o_file, ensure_ascii= True, indent= 4)\n",
    "            o_file.close()\n",
    "        elif(format == 'pkl'):\n",
    "            with open(file, 'wb') as o_file:\n",
    "                pickle.dump(data, o_file, -1)\n",
    "            o_file.close()\n",
    "        elif(format== 'hdf'):\n",
    "            data.to_hdf(path_or_buf= file, key='undefined', mode='w', complib='blosc')\n",
    "#         elif(format == 'csr'):\n",
    "#             np.savez(file, data= data['data'], indices= data['indices'], indptr= data['indptr'], shape= data['shape'])\n",
    "        elif(format == 'npz'):\n",
    "            scipy.sparse.save_npz(file, data)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-31T15:26:23.910016Z",
     "start_time": "2017-12-31T15:26:23.864187Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import sparse\n",
    "class NbSvmClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, C=1.0, dual=False, n_jobs=1):\n",
    "        self.C = C\n",
    "        self.dual = dual\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def predict(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict(x.multiply(self._r))\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        # Verify that model has been fit\n",
    "        check_is_fitted(self, ['_r', '_clf'])\n",
    "        return self._clf.predict_proba(x.multiply(self._r))\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        # Check that X and y have correct shape\n",
    "        y = y.values\n",
    "        x, y = check_X_y(x, y, accept_sparse=True)\n",
    "\n",
    "        def pr(x, y_i, y):\n",
    "            p = x[y==y_i].sum(0)\n",
    "            return (p+1) / ((y==y_i).sum()+1)\n",
    "\n",
    "        self._r = sparse.csr_matrix(np.log(pr(x,1,y) / pr(x,0,y)))\n",
    "        x_nb = x.multiply(self._r)\n",
    "        self._clf = LogisticRegression(C=self.C, dual=self.dual, n_jobs=self.n_jobs).fit(x_nb, y)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-31T15:26:23.981747Z",
     "start_time": "2017-12-31T15:26:23.912302Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mdl(x, y):\n",
    "    y = y.values\n",
    "    p_1 = x[y == 1].sum(0)\n",
    "    pr_1 = (p_1 + 1) / ((y == 1).sum() + 1)\n",
    "    p_0 = x[y == 0].sum(0)\n",
    "    pr_0 = (p_0 + 1) / ((y == 0).sum() + 1)\n",
    "    r = np.log(pr_1 / pr_0)\n",
    "    m = LogisticRegression(C= 40, dual=True)\n",
    "    x_nb = x.multiply(r)\n",
    "    return m.fit(x_nb, y), r\n",
    "\n",
    "def ComputeAUC(truth, predict):\n",
    "    ''''''\n",
    "    n = len(truth)\n",
    "    #\n",
    "    pos_num = np.sum(truth)\n",
    "    neg_num = len(truth) - pos_num\n",
    "    #\n",
    "    pairs = zip(truth, predict)\n",
    "    sorted_pairs = sorted(pairs, key= lambda x: x[1])\n",
    "    sorted_truth = [s[0] for s in sorted_pairs]\n",
    "    #\n",
    "    auc = 0.0\n",
    "    x = np.zeros((n), dtype= 'float')\n",
    "    y = np.zeros((n), dtype= 'float')\n",
    "    x[0] = 1.0\n",
    "    y[0] = 1.0\n",
    "    for i in range(1, n):\n",
    "        a = (n - i - np.sum(sorted_truth[i:n]))/neg_num\n",
    "        b = np.sum(sorted_truth[i:n])/pos_num\n",
    "        x[i] = a\n",
    "        y[i] = b\n",
    "        #print(auc)\n",
    "        auc += ((y[i] + y[i - 1]) * (x[i - 1] - x[i]))/2.0\n",
    "    auc += (y[n - 1] * x[n - 1])/2.0\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-12-31T15:33:31.165066Z",
     "start_time": "2017-12-31T15:33:09.420108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data done.\n",
      "train/valid = 65542/16386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training for fold 0 done.\n",
      "saving for fold 0 done. cv score 0.1219, holdout score 0.1354\n",
      "train/valid = 65542/16386\n",
      "training for fold 1 done.\n",
      "saving for fold 1 done. cv score 0.1345, holdout score 0.1442\n",
      "train/valid = 65542/16386\n",
      "training for fold 2 done.\n",
      "saving for fold 2 done. cv score 0.1394, holdout score 0.1514\n",
      "train/valid = 65543/16385\n",
      "training for fold 3 done.\n",
      "saving for fold 3 done. cv score 0.1351, holdout score 0.1448\n",
      "train/valid = 65543/16385\n",
      "training for fold 4 done.\n",
      "saving for fold 4 done. cv score 0.1104, holdout score 0.1212\n",
      "zip ../data/bootstrap/0/l1/submit/nbsvm_tfidf_submit_2018-01-01.zip ../data/bootstrap/0/l1/submit/nbsvm_tfidf_submit_2018-01-01.csv\n",
      "==========================================================================\n",
      "bootrap 0 done!\n",
      "cv score 0.128, cv auc score {'toxic': 0.71710678951681672, 'severe_toxic': 0.74179767777877748, 'obscene': 0.72052372893970651, 'threat': 0.64503414865299791, 'insult': 0.71807572980270229, 'identity_hate': 0.67398329690005776}\n",
      "holdout score 0.139, holdout auc score {'toxic': 0.71775940863658305, 'severe_toxic': 0.74073717732857403, 'obscene': 0.71939454912703016, 'threat': 0.63754171193543385, 'insult': 0.72652295315723658, 'identity_hate': 0.64477589741576147}\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time, os, sys\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "DataBase = '../data'\n",
    "R = 3\n",
    "K = 5\n",
    "iformat = 'npz'\n",
    "oformat = 'csv'\n",
    "algo = 'nbsvm'\n",
    "strategy = 'tfidf'\n",
    "level = 0\n",
    "ilevel = 'l%s' % level\n",
    "olevel = 'l%s' % (level + 1)\n",
    "start = time.time()\n",
    "for bid in range(R):\n",
    "    BootstrapInputDir = '%s/bootstrap/%s' % (DataBase, bid)\n",
    "    # load data\n",
    "    valid_feats = []\n",
    "    holdout_feats = []\n",
    "    test_feats = []\n",
    "    valid_xy = []\n",
    "    holdout_xy = []\n",
    "    test_xy = []\n",
    "    for fold in range(K):\n",
    "        FoldInputDir = '%s/%s/kfold/%s' % (BootstrapInputDir, ilevel, fold)\n",
    "        TFIDFInputDir = '%s/%s' % (FoldInputDir, strategy)\n",
    "        # for features\n",
    "        valid = DataUtil2.load('%s/valid_feats.%s' % (TFIDFInputDir, iformat), iformat)\n",
    "        valid_feats.append(valid)\n",
    "        holdout = DataUtil2.load('%s/holdout_feats.%s' % (TFIDFInputDir, iformat), iformat)\n",
    "        holdout_feats.append(holdout)\n",
    "        test = DataUtil2.load('%s/test_feats.%s' % (TFIDFInputDir, iformat), iformat)\n",
    "        test_feats.append(test)\n",
    "        end = time.time()\n",
    "        #print('loading features for fold %s done. time elapsed %.2fs' % (fold, (end - start)))\n",
    "        # for xy\n",
    "        valid = DataUtil2.load('%s/valid_xy.%s' % (TFIDFInputDir, 'csv'), 'csv')\n",
    "        valid['fold'] = fold\n",
    "        valid_xy.append(valid)\n",
    "        holdout = DataUtil2.load('%s/holdout_xy.%s' % (TFIDFInputDir, 'csv'), 'csv')\n",
    "        holdout_xy.append(holdout)\n",
    "        test = DataUtil2.load('%s/test_xy.%s' % (TFIDFInputDir, 'csv'), 'csv')\n",
    "        test_xy.append(test)\n",
    "        end = time.time()\n",
    "        #print('loading xy for fold %s done. time elapsed %.2fs' % (fold, (end - start)))\n",
    "    valid_xy_df = pd.concat(valid_xy, axis= 0, ignore_index= True)\n",
    "    del valid_xy\n",
    "    gc.collect()\n",
    "    print('load data done.')\n",
    "    # scores for evaluation\n",
    "    cv_score = .0\n",
    "    holdout_score = .0\n",
    "    y_test_pred = pd.DataFrame(index= range(len(test_xy[0])))\n",
    "    cv_auc_score = {}\n",
    "    holdout_auc_score = {}\n",
    "    for l in label_cols:\n",
    "        cv_auc_score[l] = .0\n",
    "        holdout_auc_score[l] = .0\n",
    "        y_test_pred[l] = .0\n",
    "    ## training\n",
    "    for fold in range(K):\n",
    "        #\n",
    "        FoldXData = {\n",
    "            'valid': valid_feats[fold],\n",
    "            'holdout': holdout_feats[fold],\n",
    "            'test': test_feats[fold]\n",
    "        }\n",
    "        FoldXData['train'] = sparse.vstack([valid_feats[i] for i in range(K) if(i != fold)], format= 'csr')\n",
    "#         print('train/valid = %s/%s' % (FoldXData['train'].shape[0], FoldXData['valid'].shape[0]))\n",
    "        #\n",
    "        FoldYData = {\n",
    "            'train': valid_xy_df[valid_xy_df['fold'] != fold],\n",
    "            'valid': valid_xy_df[valid_xy_df['fold'] == fold],\n",
    "            'holdout': holdout_xy[fold],\n",
    "            'test': test_xy[fold]\n",
    "        }\n",
    "        print('train/valid = %s/%s' % (len(FoldYData['train']), len(FoldYData['valid'])))\n",
    "        targets = []\n",
    "        cv_logerror = 0.0\n",
    "        holdout_logerror = 0.0\n",
    "        for i in range(len(label_cols)):\n",
    "            # train\n",
    "            m, r = get_mdl(FoldXData['train'], FoldYData['train'][label_cols[i]])\n",
    "#             print('fitting for %s done.' % label_cols[i])\n",
    "            target = '%s_%s_%s' % (algo, strategy, label_cols[i])\n",
    "            targets.append(target)\n",
    "            # for valid\n",
    "            FoldYData['valid'][target] = m.predict_proba(FoldXData['valid'].multiply(r))[:,1]\n",
    "            cv_logerror += -np.sum(np.log(FoldYData['valid'][target]) * FoldYData['valid'][label_cols[i]])\n",
    "            cv_auc_score[label_cols[i]] += roc_auc_score(FoldYData['valid'][label_cols[i]], FoldYData['valid'][target])\n",
    "            \n",
    "            # for valid\n",
    "            FoldYData['holdout'][target] = m.predict_proba(FoldXData['holdout'].multiply(r))[:,1]\n",
    "            holdout_logerror += -np.sum(np.log(FoldYData['holdout'][target]) * FoldYData['holdout'][label_cols[i]])\n",
    "            holdout_auc_score[label_cols[i]] += roc_auc_score(FoldYData['holdout'][label_cols[i]], FoldYData['holdout'][target])\n",
    "\n",
    "            # for test\n",
    "            FoldYData['test'][target] = m.predict_proba(FoldXData['test'].multiply(r))[:,1]\n",
    "            y_test_pred[label_cols[i]] += FoldYData['test'][target]\n",
    "            \n",
    "        print('training for fold %s done.' % fold)\n",
    "        # evaluation\n",
    "        cv_logerror /= (len(FoldYData['valid']) * len(label_cols))\n",
    "        cv_score += cv_logerror\n",
    "        holdout_logerror /= (len(FoldYData['holdout']) * len(label_cols))\n",
    "        holdout_score += holdout_logerror\n",
    "        # save\n",
    "        FoldOutputDir = '%s/%s/kfold/%s' % (BootstrapInputDir, olevel, fold)\n",
    "        if(os.path.exists(FoldOutputDir) == False):\n",
    "            os.makedirs(FoldOutputDir)\n",
    "        for mod in FoldYData.keys():\n",
    "            if(mod == 'train'):\n",
    "                continue\n",
    "            OutputFile = '%s/%s_%s_%s.%s' % (FoldOutputDir, mod, algo, strategy, oformat)\n",
    "            DataUtil2.save(FoldYData[mod][targets], OutputFile, oformat)\n",
    "        print('saving for fold %s done. cv score %.4f, holdout score %.4f' % (fold, cv_logerror, holdout_logerror))\n",
    "    cv_score /= K\n",
    "    holdout_score /= K\n",
    "    for l in label_cols:\n",
    "        cv_auc_score[l] /= K\n",
    "        holdout_auc_score[l] /= K\n",
    "        y_test_pred[l] /= K\n",
    "        \n",
    "    # Create submission file\n",
    "    sub = pd.DataFrame()\n",
    "    sub['id'] = test_xy[0]['id']\n",
    "    for l in label_cols:\n",
    "        sub[l] = y_test_pred[l]\n",
    "    OutputFileName = '%s_%s_submit_%s' % (algo, strategy, datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    SubmitDir = '%s/%s/submit' % (BootstrapInputDir, olevel)\n",
    "    if(os.path.exists(SubmitDir) == False):\n",
    "        os.makedirs(SubmitDir)\n",
    "    sub.to_csv('%s/%s.csv' % (SubmitDir, OutputFileName), float_format='%.6f', index=False)\n",
    "    print('zip %s/%s.zip %s/%s.csv' % (SubmitDir, OutputFileName, SubmitDir, OutputFileName))\n",
    "    os.system('zip %s/%s.zip %s/%s.csv' % (SubmitDir, OutputFileName, SubmitDir, OutputFileName))\n",
    "    \n",
    "    print('==========================================================================')\n",
    "    print('bootrap %s done!' % bid)\n",
    "    print('cv score %.3f, cv auc score %s' % (cv_score, cv_auc_score))\n",
    "    print('holdout score %.3f, holdout auc score %s' % (holdout_score, holdout_auc_score))\n",
    "    print('==========================================================================')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
