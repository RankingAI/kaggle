{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-14T19:31:27.742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 done.\n",
      "fold 1 done.\n",
      "fold 2 done.\n",
      "fold 3 done.\n",
      "load data done, train 159571\n",
      "[load data] done in 4 s\n",
      "==================================\n",
      "loading data done.\n",
      "==================================\n",
      "\n",
      "====================================\n",
      "total features size 44, sample size 159571\n",
      "==================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:118: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:121: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "#Forward Greedy Feature selection#\n",
    "##################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os,sys\n",
    "import gc\n",
    "from sklearn import *\n",
    "from itertools import combinations\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.special import erfinv\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    \"\"\"\n",
    "    Taken from Konstantin Lopuhin https://www.kaggle.com/lopuhin\n",
    "    in script named : Mercari Golf: 0.3875 CV in 75 LOC, 1900 s\n",
    "    https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')\n",
    "\n",
    "DataBaseDir = '../../data/version2'\n",
    "InputDir = '%s/l1/kfold' % DataBaseDir\n",
    "# MetaInputDir = '%s/meta/kfold' % DataBaseDir\n",
    "kfold = 4\n",
    "seed_num = 1\n",
    "verbose = True\n",
    "has_snapshot = False\n",
    "attention = 'meta'\n",
    "datestr = '%s' % datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "targets = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "strategy = 'lr'\n",
    "meta_models = ['bi-gru', 'bi-lstm', 'bi-gru-cnn',\n",
    "               'fm-ftrl', 'lgb', 'lr', 'nbsvm', 'bi-lstm-attention', 'bi-gru-capsule', 'bi-lstm-cnn-2']\n",
    "drop_cols = ['id', 'fold']\n",
    "\n",
    "num_cols = []\n",
    "# load data\n",
    "valid_dfs = []\n",
    "with timer('load data'):\n",
    "    for fold in range(kfold):\n",
    "        FoldInputDir = '%s/%s' % (InputDir, fold)\n",
    "        for i in range(len(meta_models)):\n",
    "            valid = pd.read_csv('%s/valid_%s.csv' % (FoldInputDir, meta_models[i])).reset_index(drop= True)\n",
    "            if(i == 0):\n",
    "                FoldValid = valid\n",
    "            else:\n",
    "                for t in targets:\n",
    "                    target = '%s_%s' % (meta_models[i], t)\n",
    "                    FoldValid[target] = valid[target].copy()\n",
    "            ##\n",
    "        NumFoldInputDir = '%s/num/kfold/%s' % (DataBaseDir, fold)\n",
    "        NumValid = pd.read_csv('%s/valid.csv' % NumFoldInputDir).reset_index(drop= True)\n",
    "        TmpNumCols = []\n",
    "        for c in NumValid.columns:\n",
    "            tmp_drop_cols = drop_cols.copy()\n",
    "            tmp_drop_cols.extend(targets)\n",
    "            if(c not in tmp_drop_cols):\n",
    "                FoldValid[c] = NumValid[c]\n",
    "                TmpNumCols.append(c)\n",
    "        num_cols = TmpNumCols\n",
    "        FoldValid['fold'] = fold\n",
    "        valid_dfs.append(FoldValid)\n",
    "        print('fold %s done.' % fold)\n",
    "    TrainData = pd.concat(valid_dfs, axis= 0, ignore_index= True)\n",
    "    print('load data done, train %s' % (len(TrainData)))\n",
    "print('==================================')\n",
    "print('loading data done.')\n",
    "print('==================================\\n')\n",
    "\n",
    "####\n",
    "all_feats = []\n",
    "#all_feats.extend(['meta_%s' % (c) for c in meta_models])\n",
    "all_feats.extend(num_cols)\n",
    "\n",
    "## GaussRank Normalization\n",
    "for c in num_cols:\n",
    "    rank = np.argsort(TrainData[c], axis= 0)\n",
    "    upper = np.max(rank)\n",
    "    lower = np.min(rank)\n",
    "    # linear normalization to 0-1\n",
    "    TrainData[c] = (TrainData[c] - lower)/(upper - lower)\n",
    "    # gauss normalization\n",
    "    TrainData[c] = erfinv(TrainData[c])\n",
    "    TrainData[c] -= np.mean(TrainData[c])\n",
    "\n",
    "pred_targets = ['%s_%s' % (strategy, t) for t in targets]\n",
    "def EvaluateFeature(cur_feat, feats):\n",
    "    cv_score = .0\n",
    "    #with timer('evaluatation for %s' % cur_feat):\n",
    "    for fold in range(kfold):\n",
    "        FoldData = {\n",
    "            'train': TrainData[TrainData['fold'] != fold],\n",
    "            'valid': TrainData[TrainData['fold'] == fold]\n",
    "        }\n",
    "        for target in targets:\n",
    "            cols = []\n",
    "            for c in feats:\n",
    "                if(c.startswith('meta')):\n",
    "                    cols.append('%s_%s' % (c[5:], target)) ## meta models\n",
    "                else:\n",
    "                    cols.append(c) ## other numeric features\n",
    "            #cols = ['%s_%s' % (c, target) for c in feats ]\n",
    "            model = linear_model.SGDClassifier(loss= 'log', \n",
    "                                                alpha= 0.004, \n",
    "                                                l1_ratio= 0.15, \n",
    "                                                max_iter= 5)\n",
    "            model.fit(FoldData['train'][cols], FoldData['train'][target])\n",
    "            # for valid\n",
    "            pred_target = '%s_%s' % (strategy, target)\n",
    "            FoldData['valid'][pred_target] = model.predict_proba(FoldData['valid'][cols])[:,1]\n",
    "            # for test\n",
    "            pred_valid = model.predict_proba(FoldData['valid'][cols])[:,1]\n",
    "            FoldData['valid'][pred_target] = pred_valid\n",
    "        score = roc_auc_score(FoldData['valid'][targets], FoldData['valid'][pred_targets])\n",
    "        cv_score += score\n",
    "    return cv_score/kfold\n",
    "\n",
    "print('====================================')\n",
    "print('total features size %s, sample size %s' % (len(all_feats), len(TrainData)))\n",
    "print('==================================\\n')\n",
    "\n",
    "start = time.time()\n",
    "score_history = []\n",
    "good_features = set([])\n",
    "OutputDir = '%s/gfs/%s' % (DataBaseDir, attention)\n",
    "if(os.path.exists(OutputDir) == False):\n",
    "    os.makedirs(OutputDir)\n",
    "if(has_snapshot):\n",
    "    with open('%s/good_features_%s.txt' % (OutputDir, datestr), 'r') as o_feat, open('%s/score_history_%s.txt' % (OutputDir, datestr), 'r') as o_score:\n",
    "        for line in o_feat:\n",
    "            good_features.add(line.rstrip())\n",
    "        for line in o_score:\n",
    "            parts = line.rstrip().split(',')\n",
    "            score_history.append((float(parts[0]), parts[1]))\n",
    "    o_feat.close()\n",
    "    o_score.close()\n",
    "    print('loading good feature snapshot done.')\n",
    "while ((len(score_history) < 2) or (score_history[-1][0] > score_history[-2][0])):\n",
    "    scores = []\n",
    "    for feature in all_feats:\n",
    "        if feature not in good_features:\n",
    "            selected_features = list(good_features) + [feature]\n",
    "#             print('evaluation for %s begins...' % feature)\n",
    "            score = EvaluateFeature(feature[5:], selected_features)\n",
    "            scores.append((score, feature))\n",
    "    if(len(scores) == 0):\n",
    "        break\n",
    "    selected = sorted(scores)[-1]\n",
    "    current_feat = selected[1]\n",
    "    current_score = selected[0]\n",
    "    good_features.add(current_feat)\n",
    "    score_history.append(selected)\n",
    "    end = time.time()\n",
    "    if verbose:\n",
    "        improved_score = .0\n",
    "        if(len(score_history) > 1):\n",
    "            improved_score = score_history[-1][0] - score_history[-2][0]\n",
    "        print('====================================')\n",
    "        print('Current master %s, improve score %.5f, time elapsed %.2fs' % (current_feat, improved_score, (end - start)))\n",
    "        print('====================================\\n')\n",
    "    with open('%s/good_features_%s.txt' % (OutputDir, datestr), 'w') as o_feat, open('%s/score_history_%s.txt' % (OutputDir, datestr), 'w') as o_score:\n",
    "        for feat in good_features:\n",
    "            o_feat.write('%s\\n' % feat)\n",
    "        for score, feat in score_history:\n",
    "            o_score.write('%s,%s\\n' % (str(score), feat))\n",
    "    o_feat.close()\n",
    "    o_score.close()\n",
    "\n",
    "# Remove the last added feature if necessary\n",
    "if(score_history[-1][0] < score_history[-2][0]):\n",
    "    good_features.remove(score_history[-1][1])\n",
    "good_features = sorted(list(good_features))\n",
    "if verbose:\n",
    "    print(\"Selected Features : \", good_features)\n",
    "    \n",
    "with open('%s/good_features_%s.txt' % (OutputDir, datestr), 'w') as o_feat, open('%s/score_history_%s.txt' % (OutputDir, datestr), 'w') as o_score:\n",
    "    for feat in good_features:\n",
    "        o_feat.write('%s\\n' % feat)\n",
    "    for score, feat in score_history:\n",
    "        o_score.write('%s,%s\\n' % (str(score), feat))\n",
    "o_feat.close()\n",
    "o_score.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
