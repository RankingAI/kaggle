{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T08:49:47.710116Z",
     "start_time": "2018-03-09T08:49:44.430227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data for fold 0 done.\n",
      "load data for fold 1 done.\n",
      "load data for fold 2 done.\n",
      "load data done, train 143591 holdout 15980, time elapsed 0.9921886920928955\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import os,sys,time,datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "DataBaseDir = '../../data/version1'\n",
    "InputDir = '%s/l0/kfold' % DataBaseDir\n",
    "OutputDir = '%s/l1' % DataBaseDir\n",
    "kfold = 3\n",
    "strategy = 'bi-gru'\n",
    "# load data\n",
    "start = time.time()\n",
    "valid_dfs = []\n",
    "for fold in range(kfold):\n",
    "    FoldInputDir = '%s/%s' % (InputDir, fold)\n",
    "    valid = pd.read_csv('%s/valid.csv' % FoldInputDir).reset_index(drop= True)#.sample(frac= 0.1)\n",
    "    ## for valid/holdout data set\n",
    "    if(fold == 0):\n",
    "        HoldoutData = pd.read_csv('%s/holdout.csv' % FoldInputDir).reset_index(drop= True)#.sample(frac= 0.1)\n",
    "        TestData = pd.read_csv('%s/test.csv' % FoldInputDir).reset_index(drop= True)#.sample(frac= 0.1)\n",
    "    valid['fold'] = fold\n",
    "    valid_dfs.append(valid)\n",
    "    print('load data for fold %s done.' % fold)\n",
    "TrainData = pd.concat(valid_dfs, axis= 0, ignore_index= True)\n",
    "end = time.time()\n",
    "print('load data done, train %s holdout %s, time elapsed %s' % (len(TrainData), len(HoldoutData), (end - start)))\n",
    "##\n",
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def LoadEmbeddingVectors(f):\n",
    "    ## debug\n",
    "    k = 1000\n",
    "    EmbeddingDict = {}\n",
    "    with open(f, 'r') as i_file:\n",
    "        for line in i_file:\n",
    "            #if(k == 0):\n",
    "            #    break\n",
    "            w, coe_vec= get_coefs(*line.rstrip().rsplit(' '))\n",
    "            EmbeddingDict[w] = coe_vec\n",
    "            k -= 1\n",
    "    i_file.close()\n",
    "    return EmbeddingDict\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "targets = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "EmbeddingFile = '../../data/raw/crawl-300d-2M.vec'\n",
    "max_features = 30000\n",
    "maxlen = 100\n",
    "#max_features = 3000\n",
    "#maxlen = 10\n",
    "embed_size = 300\n",
    "batch_size = 16\n",
    "epochs = 2\n",
    "start = time.time()\n",
    "EmbeddingIndex = LoadEmbeddingVectors(EmbeddingFile)\n",
    "end = time.time()\n",
    "print('load embedding features done, corpus size %s, time elapsed %s' % (len(EmbeddingIndex), (end - start)))\n",
    "\n",
    "def get_model(embedding_matrix):\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "##\n",
    "cv_score = .0\n",
    "start = time.time()\n",
    "pred_cols = ['%s_%s' % (strategy, c) for c in targets]\n",
    "for c in pred_cols:\n",
    "    HoldoutData[c] = .0\n",
    "    TestData[c] = .0\n",
    "for fold in range(kfold):\n",
    "    print('====== fold %s ======\\n' % fold)\n",
    "    FoldData = {\n",
    "        'train': TrainData[TrainData['fold'] != fold],\n",
    "        'valid': TrainData[TrainData['fold'] == fold],\n",
    "        'holdout': HoldoutData,\n",
    "        'test': TestData\n",
    "    }\n",
    "    for c in pred_cols:\n",
    "        FoldData['valid'][c] = .0\n",
    "        FoldData['holdout'][c] = .0\n",
    "        FoldData['test'][c] = .0\n",
    "    ## tokenize with entire corpus composed by train/valid/holdout\n",
    "    tokenizer = text.Tokenizer(num_words= max_features)\n",
    "    EntireCorpus = list(FoldData['train']['comment_text'].values) + list(FoldData['valid']['comment_text'].values) + list(FoldData['holdout']['comment_text'].values) + list(FoldData['test']['comment_text'].values)\n",
    "    tokenizer.fit_on_texts(EntireCorpus)\n",
    "    X_train = tokenizer.texts_to_sequences(FoldData['train']['comment_text'].values)\n",
    "    X_valid = tokenizer.texts_to_sequences(FoldData['valid']['comment_text'].values)\n",
    "    X_holdout = tokenizer.texts_to_sequences(FoldData['holdout']['comment_text'].values)\n",
    "    X_test = tokenizer.texts_to_sequences(FoldData['test']['comment_text'].values)\n",
    "    X_train = sequence.pad_sequences(X_train, maxlen= maxlen)\n",
    "    X_valid = sequence.pad_sequences(X_valid, maxlen= maxlen)\n",
    "    X_holdout = sequence.pad_sequences(X_holdout, maxlen= maxlen)\n",
    "    X_test = sequence.pad_sequences(X_test, maxlen= maxlen)\n",
    "    Y_train = FoldData['train'][targets].values\n",
    "    Y_valid = FoldData['valid'][targets].values\n",
    "    #Y_holdout = FoldData['holdout'][targets].values\n",
    "    end = time.time()\n",
    "    print('token done, time elapsed %s.' % (end - start))\n",
    "    ## embedding with pre-trained embedding library\n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = EmbeddingIndex.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    end = time.time()\n",
    "    print('embedding done, time elapsed %s.' % (end - start))\n",
    "    ## construct bi-gru model\n",
    "    start = time.time()\n",
    "    model = get_model(embedding_matrix)\n",
    "    RocAuc = RocAucEvaluation(validation_data= (X_valid, Y_valid), interval=1)\n",
    "    hist = model.fit(X_train, Y_train, \n",
    "                     batch_size= batch_size, \n",
    "                     epochs= epochs, \n",
    "                     validation_data= (X_valid, Y_valid),\n",
    "                     callbacks=[RocAuc], verbose=2)\n",
    "    end = time.time()\n",
    "    print('fitting done, time elapsed %s.' % (end - start))\n",
    "    ## predict for valid\n",
    "    pred_valid = model.predict(X_valid, batch_size=1024)\n",
    "    FoldData['valid'][pred_cols] = pred_valid\n",
    "    ## predict for holdout\n",
    "    pred_holdout = model.predict(X_holdout, batch_size=1024)\n",
    "    FoldData['holdout'][pred_cols] = pred_holdout\n",
    "    HoldoutData[pred_cols] += pred_holdout\n",
    "    ## predict for test\n",
    "    pred_test = model.predict(X_test, batch_size=1024)\n",
    "    FoldData['test'][pred_cols] = pred_test\n",
    "    TestData[pred_cols] += pred_test\n",
    "    end = time.time()\n",
    "    print('predict done, time elapsed %s.' % (end - start))\n",
    "    ## evaluate\n",
    "    print(FoldData['valid'][pred_cols].isnull().sum(axis= 0))\n",
    "    score = roc_auc_score(FoldData['valid'][targets], FoldData['valid'][pred_cols])\n",
    "    cv_score += score\n",
    "    print('fold %s, score %.5f' % (fold, score))\n",
    "    ## output\n",
    "    FoldOutputDir = '%s/kfold/%s' % (OutputDir, fold)\n",
    "    if(os.path.exists(FoldOutputDir) == False):\n",
    "        os.makedirs(FoldOutputDir)\n",
    "    for mod in ['valid', 'holdout', 'test']:\n",
    "        if(mod == 'test'):\n",
    "            out_cols = ['id']\n",
    "            out_cols.extend(pred_cols)\n",
    "        else:\n",
    "            out_cols = pred_cols.copy()\n",
    "            out_cols.extend(targets)\n",
    "        FoldData[mod][out_cols].to_csv('%s/%s.csv' % (FoldOutputDir, mod),float_format='%.6f', index= False) \n",
    "    end = time.time()\n",
    "    print('output done, time elapsed %s.\\n' % (end - start))\n",
    "cv_score /= kfold\n",
    "HoldoutData[pred_cols] /= kfold\n",
    "TestData[pred_cols] /= kfold\n",
    "holdout_score = roc_auc_score(HoldoutData[targets], HoldoutData[pred_cols])\n",
    "end = time.time()\n",
    "print('\\n================')\n",
    "print('cv score %.5f, holdout score %.5f, time elapsed %s' % (cv_score, holdout_score, (end - start)))\n",
    "print('================')\n",
    "\n",
    "## submit\n",
    "sub = TestData[['id']].copy()\n",
    "sub[targets] = TestData[pred_cols]\n",
    "OutputFileName = '%s_submit_%s' % (strategy, datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "SubmitDir = '%s/l0/submit' % DataBaseDir\n",
    "if(os.path.exists(SubmitDir) == False):\n",
    "    os.makedirs(SubmitDir)\n",
    "sub.to_csv('%s/%s.csv' % (SubmitDir, OutputFileName), float_format='%.6f', index=False)\n",
    "print('zip %s/%s.zip %s/%s.csv' % (SubmitDir, OutputFileName, SubmitDir, OutputFileName))\n",
    "os.system('zip %s/%s.zip %s/%s.csv' % (SubmitDir, OutputFileName, SubmitDir, OutputFileName))\n",
    "\n",
    "print('\\n======================')\n",
    "print(\"CV score %.4f, Holdout score %.4f\" % (cv_score, holdout_score))\n",
    "print('======================\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
