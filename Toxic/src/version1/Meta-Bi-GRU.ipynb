{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T08:49:47.710116Z",
     "start_time": "2018-03-09T08:49:44.430227Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import os,sys,time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T09:17:18.509963Z",
     "start_time": "2018-03-09T09:16:29.845028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data for fold 0 done.\n",
      "load data for fold 1 done.\n",
      "load data for fold 2 done.\n",
      "load data done, train 143591 holdout 15980, time elapsed 0.926793098449707\n",
      "load embedding features done, corpus size 5000, time elapsed 0.3693718910217285\n",
      "====== fold 0 ======\n",
      "\n",
      "token done, time elapsed 19.210576057434082.\n",
      "embedding done, time elapsed 19.279154777526855.\n",
      "Train on 95716 samples, validate on 47875 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-81e455501cd8>\", line 125, in <module>\n",
      "    callbacks=[RocAuc], verbose=2)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1598, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1183, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2273, in __call__\n",
      "    **self.session_kwargs)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 778, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 982, in _run\n",
      "    feed_dict_string, options, run_metadata)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1032, in _do_run\n",
      "    target_list, options, run_metadata)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1039, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1021, in _run_fn\n",
      "    status, run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1806, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/inspect.py\", line 1415, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 165, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/inspect.py\", line 666, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Users/yuanpingzhou/miniconda3/lib/python3.6/inspect.py\", line 703, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "DataBaseDir = '../../data/version1'\n",
    "InputDir = '%s/l0/kfold' % DataBaseDir\n",
    "OutputDir = '%s/l1/kfold' % DataBaseDir\n",
    "kfold = 3\n",
    "strategy = 'bi-gru'\n",
    "# load data\n",
    "start = time.time()\n",
    "valid_dfs = []\n",
    "for fold in range(kfold):\n",
    "    FoldInputDir = '%s/%s' % (InputDir, fold)\n",
    "    valid = pd.read_csv('%s/valid.csv' % FoldInputDir).reset_index(drop= True)\n",
    "    ## for valid/holdout data set\n",
    "    if(fold == 0):\n",
    "        HoldoutData = pd.read_csv('%s/holdout.csv' % FoldInputDir).reset_index(drop= True)\n",
    "    valid['fold'] = fold\n",
    "    valid_dfs.append(valid)\n",
    "    print('load data for fold %s done.' % fold)\n",
    "TrainData = pd.concat(valid_dfs, axis= 0, ignore_index= True)\n",
    "end = time.time()\n",
    "print('load data done, train %s holdout %s, time elapsed %s' % (len(TrainData), len(HoldoutData), (end - start)))\n",
    "##\n",
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "def LoadEmbeddingVectors(f):\n",
    "    ## debug\n",
    "    k = 5000\n",
    "    EmbeddingDict = {}\n",
    "    with open(f, 'r') as i_file:\n",
    "        for line in i_file:\n",
    "            if(k == 0):\n",
    "                break\n",
    "            w, coe_vec= get_coefs(*line.rstrip().rsplit(' '))\n",
    "            EmbeddingDict[w] = coe_vec\n",
    "            k -= 1\n",
    "    i_file.close()\n",
    "    return EmbeddingDict\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "targets = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "EmbeddingFile = '../../data/raw/crawl-300d-2M.vec'\n",
    "max_features = 30000\n",
    "maxlen = 100\n",
    "embed_size = 300\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "start = time.time()\n",
    "EmbeddingIndex = LoadEmbeddingVectors(EmbeddingFile)\n",
    "end = time.time()\n",
    "print('load embedding features done, corpus size %s, time elapsed %s' % (len(EmbeddingIndex), (end - start)))\n",
    "\n",
    "def get_model(embedding_matrix):\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cv_score = .0\n",
    "holdout_score = .0\n",
    "start = time.time()\n",
    "for fold in range(kfold):\n",
    "    print('====== fold %s ======\\n' % fold)\n",
    "    FoldData = {\n",
    "        'train': TrainData[TrainData['fold'] != fold],\n",
    "        'valid': TrainData[TrainData['fold'] == fold],\n",
    "        'holdout': HoldoutData\n",
    "    }\n",
    "    ## tokenize with entire corpus composed by train/valid/holdout\n",
    "    tokenizer = text.Tokenizer(num_words= max_features)\n",
    "    EntireCorpus = list(FoldData['train']['comment_text'].values) + list(FoldData['valid']['comment_text'].values) + list(FoldData['holdout']['comment_text'].values)\n",
    "    tokenizer.fit_on_texts(EntireCorpus)\n",
    "    X_train = tokenizer.texts_to_sequences(FoldData['train']['comment_text'].values)\n",
    "    X_valid = tokenizer.texts_to_sequences(FoldData['valid']['comment_text'].values)\n",
    "    X_holdout = tokenizer.texts_to_sequences(FoldData['holdout']['comment_text'].values)\n",
    "    X_train = sequence.pad_sequences(X_train, maxlen= maxlen)\n",
    "    X_valid = sequence.pad_sequences(X_valid, maxlen= maxlen)\n",
    "    X_holdout = sequence.pad_sequences(X_holdout, maxlen= maxlen)\n",
    "    Y_train = FoldData['train'][targets].values\n",
    "    Y_valid = FoldData['valid'][targets].values\n",
    "    Y_holdout = FoldData['holdout'][targets].values\n",
    "    end = time.time()\n",
    "    print('token done, time elapsed %s.' % (end - start))\n",
    "    ## embedding with pre-trained embedding library\n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = EmbeddingIndex.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    end = time.time()\n",
    "    print('embedding done, time elapsed %s.' % (end - start))\n",
    "    ## construct bi-gru model\n",
    "    start = time.time()\n",
    "    model = get_model(embedding_matrix)\n",
    "    RocAuc = RocAucEvaluation(validation_data= (X_valid, Y_valid), interval=1)\n",
    "    hist = model.fit(X_train, Y_train, \n",
    "                     batch_size= batch_size, \n",
    "                     epochs= epochs, \n",
    "                     validation_data= (X_valid, Y_valid),\n",
    "                     callbacks=[RocAuc], verbose=2)\n",
    "    end = time.time()\n",
    "    print('fitting done, time elapsed %s.' % (end - start))\n",
    "    ## predict\n",
    "    pred_cols = ['%s_%s' % (strategy, c) for c in targets]\n",
    "    FoldInputDir['valid'][pred_cols] = model.predict(X_valid, batch_size=1024)\n",
    "    FoldInputDir['holdout'][pred_cols] = model.predict(X_holdout, batch_size=1024)\n",
    "    end = time.time()\n",
    "    print('predict done, time elapsed %s.' % (end - start))\n",
    "    ## evaluate\n",
    "    cv_score += roc_auc_score(FoldInputDir['valid'][pred_cols], FoldInputDir['valid'][targets])\n",
    "    holdout_score += roc_auc_score(FoldInputDir['holdout'][pred_cols], FoldInputDir['holdout'][targets])\n",
    "    ## output\n",
    "    FoldOutputDir = '%s/%s' % (OutputDir, fold)\n",
    "    if(os.path.exists(FoldOutputDir) == False):\n",
    "        os.makedirs(FoldOutputDir)\n",
    "    out_cols = pred_cols.extend(targets)\n",
    "    for mod in ['valid', 'holdout']:\n",
    "        FoldData[mod][out_cols].to_csv('%s/%s.csv' % (FoldOutputDir, mod))\n",
    "    end = time.time()\n",
    "    print('output done, time elapsed %s.\\n' % (end - start))\n",
    "cv_score /= kfold\n",
    "holdout_score /= kfold\n",
    "end = time.time()\n",
    "print('\\n================')\n",
    "print('cv score %.5f, holdout score %.5f, time elapsed %s' % (cv_score, holdout_score, (end - start)))\n",
    "print('================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
