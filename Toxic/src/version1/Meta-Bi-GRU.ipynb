{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T07:59:44.304171Z",
     "start_time": "2018-03-09T07:59:44.287002Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import os,sys,time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-09T07:59:45.207991Z",
     "start_time": "2018-03-09T07:59:44.305741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data for fold 0 done.\n",
      "load data for fold 1 done.\n",
      "load data for fold 2 done.\n",
      "load data done, train 143591 holdout 15980, time elapsed 0.8826570510864258\n"
     ]
    }
   ],
   "source": [
    "DataBaseDir = '../../data/version1'\n",
    "InputDir = '%s/l0/kfold' % DataBaseDir\n",
    "OutputDir = '%s/l1/kfold' % DataBaseDir\n",
    "kfold = 3\n",
    "strategy = 'bi-gru'\n",
    "# load data\n",
    "start = time.time()\n",
    "valid_dfs = []\n",
    "for fold in range(kfold):\n",
    "    FoldInputDir = '%s/%s' % (InputDir, fold)\n",
    "    valid = pd.read_csv('%s/valid.csv' % FoldInputDir).reset_index(drop= True)\n",
    "    ## for valid/holdout data set\n",
    "    if(fold == 0):\n",
    "        HoldoutData = pd.read_csv('%s/holdout.csv' % FoldInputDir).reset_index(drop= True)\n",
    "    valid['fold'] = fold\n",
    "    valid_dfs.append(valid)\n",
    "    print('load data for fold %s done.' % fold)\n",
    "TrainData = pd.concat(valid_dfs, axis= 0, ignore_index= True)\n",
    "end = time.time()\n",
    "print('load data done, train %s holdout %s, time elapsed %s' % (len(TrainData), len(HoldoutData), (end - start)))\n",
    "##### model selection with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-09T08:00:23.164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n"
     ]
    }
   ],
   "source": [
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "\n",
    "targets = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "EmbeddingFile = '../../data/raw/crawl-300d-2M.vec'\n",
    "max_features = 30000\n",
    "maxlen = 100\n",
    "embed_size = 300\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "start = time.time()\n",
    "EmbeddingInidex = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EmbeddingFile))\n",
    "end = time.time()\n",
    "print('load embedding features done, corpus size %s, time elapsed %s' % (len(EmbeddingInidex), (end - start)))\n",
    "\n",
    "def get_model(embedding_matrix):\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    conc = concatenate([avg_pool, max_pool])\n",
    "    outp = Dense(6, activation=\"sigmoid\")(conc)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=outp)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "for fold in range(kfold):\n",
    "    print('=============== fold %s ==============\\n')\n",
    "    FoldData = {\n",
    "        'train': TrainData[TrainData['fold'] != fold],\n",
    "        'valid': TrainData[TrainData['fold'] == fold],\n",
    "        'holdout': HoldoutData\n",
    "    }\n",
    "    ## tokenize with entire corpus composed by train/valid/holdout\n",
    "    tokenizer = text.Tokenizer(num_words= max_features)\n",
    "    EntireCorpus = list(FoldData['train']['comment_text'].values) + list(FoldData['valid']['comment_text'].values) + list(FoldData['test']['comment_text'].values)\n",
    "    tokenizer.fit_on_texts(EntireCorpus)\n",
    "    X_train = tokenizer.texts_to_sequences(FoldData['train']['comment_text'].values)\n",
    "    X_valid = tokenizer.texts_to_sequences(FoldData['valid']['comment_text'].values)\n",
    "    X_holdout = tokenizer.texts_to_sequences(FoldData['holdout']['comment_text'].values)\n",
    "    X_train = sequence.pad_sequences(X_train, maxlen= maxlen)\n",
    "    X_valid = sequence.pad_sequences(X_valid, maxlen= maxlen)\n",
    "    X_holdout = sequence.pad_sequences(X_holdout, maxlen= maxlen)\n",
    "    Y_train = FoldData['train'][targets].values\n",
    "    Y_valid = FoldData['valid'][targets].values\n",
    "    Y_holdout = FoldData['holdout'][targets].values\n",
    "    print('token done.')\n",
    "    ## embedding with pre-trained embedding library\n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    print('embedding done.')\n",
    "    ## construct bi-gru model\n",
    "    model = get_model(embedding_matrix)\n",
    "    hist = model.fit(X_train, Y_train, \n",
    "                     batch_size= batch_size, \n",
    "                     epochs= epochs, \n",
    "                     validation_data= (X_valid, Y_valid),\n",
    "                     callbacks=[RocAuc], verbose=2)\n",
    "    print('fitting done.')\n",
    "    Y_holdout_pred = model.predict(X_holdout, batch_size=1024)\n",
    "    print('predict done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
