{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-19T03:20:43.812123Z",
     "start_time": "2018-01-19T03:04:09.515267Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 188 models for meta_trees_25_500.\n",
      "top 214 models for meta_trees_50_500.\n",
      "top 204 models for meta_trees_75_500.\n",
      "fold 0 done, time elapsed 108.97383618354797s\n",
      "fold 1 done, time elapsed 219.16406297683716s\n",
      "fold 2 done, time elapsed 328.4018130302429s\n",
      "fold 3 done, time elapsed 438.42561888694763s\n",
      "fold 4 done, time elapsed 549.727949142456s\n",
      "----------------- CHECK -------------\n",
      "\n",
      "============================ TrainData\n",
      "           air_store_id visit_date  visitors  lgb_l2_meta_trees_25_500_17  \\\n",
      "0  air_ba937bf13d40fb24 2016-01-15  3.401197                     3.388881   \n",
      "1  air_ba937bf13d40fb24 2016-01-29  3.295837                     3.345007   \n",
      "2  air_ba937bf13d40fb24 2016-01-30  1.945910                     3.152395   \n",
      "3  air_ba937bf13d40fb24 2016-02-10  3.496508                     3.267363   \n",
      "4  air_ba937bf13d40fb24 2016-02-13  2.197225                     3.097088   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_31  lgb_l2_meta_trees_25_500_57  \\\n",
      "0                     3.435833                     3.468708   \n",
      "1                     3.410471                     3.413966   \n",
      "2                     3.204999                     3.216375   \n",
      "3                     3.372801                     3.330070   \n",
      "4                     3.143488                     3.109850   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_0  lgb_l2_meta_trees_25_500_43  \\\n",
      "0                    3.438313                     3.397252   \n",
      "1                    3.422763                     3.385114   \n",
      "2                    3.204880                     3.213924   \n",
      "3                    3.347017                     3.322883   \n",
      "4                    3.113005                     3.163245   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_108  lgb_l2_meta_trees_25_500_85  ...   lgb_fair  \\\n",
      "0                      3.478044                     3.435834  ...   3.466606   \n",
      "1                      3.445958                     3.397364  ...   3.414985   \n",
      "2                      3.263302                     3.211756  ...   3.297721   \n",
      "3                      3.409308                     3.272897  ...   3.350490   \n",
      "4                      3.170720                     3.137197  ...   3.227915   \n",
      "\n",
      "        etr        en        rf    gbr_ls  gbr_huber   gbr_lad  lassolars  \\\n",
      "0  3.522412  3.446830  3.390379  3.453311   3.531606  3.472406   3.435844   \n",
      "1  3.357368  3.421253  3.383019  3.477916   3.429893  3.489702   3.403081   \n",
      "2  3.237563  3.191579  3.277727  3.256024   3.249575  3.268547   3.197487   \n",
      "3  3.273555  3.381559  3.231127  3.347062   3.261230  3.376480   3.352976   \n",
      "4  3.129093  3.137173  3.250191  3.252635   3.258257  3.143148   3.136183   \n",
      "\n",
      "        rgf  fold  \n",
      "0  3.497157     0  \n",
      "1  3.495588     0  \n",
      "2  3.271060     0  \n",
      "3  3.371899     0  \n",
      "4  3.252454     0  \n",
      "\n",
      "[5 rows x 622 columns]\n",
      "\n",
      "============================ HoldoutData\n",
      "           air_store_id visit_date  visitors  lgb_l2_meta_trees_25_500_17  \\\n",
      "0  air_ba937bf13d40fb24 2016-01-13  3.258097                     2.849893   \n",
      "1  air_ba937bf13d40fb24 2016-02-05  3.828641                     3.361694   \n",
      "2  air_ba937bf13d40fb24 2016-02-08  2.995732                     2.550955   \n",
      "3  air_ba937bf13d40fb24 2016-02-16  2.772589                     2.957737   \n",
      "4  air_ba937bf13d40fb24 2016-02-19  3.784190                     3.375606   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_31  lgb_l2_meta_trees_25_500_57  \\\n",
      "0                     2.921985                     2.913329   \n",
      "1                     3.418856                     3.413580   \n",
      "2                     2.508734                     2.502656   \n",
      "3                     2.972300                     2.919035   \n",
      "4                     3.428448                     3.418129   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_0  lgb_l2_meta_trees_25_500_43  \\\n",
      "0                    2.880980                     2.878457   \n",
      "1                    3.417910                     3.427107   \n",
      "2                    2.503486                     2.516006   \n",
      "3                    2.939986                     2.942304   \n",
      "4                    3.437176                     3.422260   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_108  lgb_l2_meta_trees_25_500_85    ...     \\\n",
      "0                      2.928253                     2.813721    ...      \n",
      "1                      3.445679                     3.387124    ...      \n",
      "2                      2.485715                     2.575496    ...      \n",
      "3                      2.932109                     2.883670    ...      \n",
      "4                      3.449955                     3.391862    ...      \n",
      "\n",
      "   lgb_huber  lgb_fair       etr        en        rf    gbr_ls  gbr_huber  \\\n",
      "0   2.957470  2.978194  2.968943  2.968541  3.051428  2.913647   2.894706   \n",
      "1   3.402463  3.385146  3.340617  3.410915  3.381694  3.456725   3.436673   \n",
      "2   2.533538  2.502592  2.560835  2.469497  2.605700  2.653010   2.586020   \n",
      "3   2.931980  2.905917  2.920379  2.928325  2.884706  2.966331   2.895896   \n",
      "4   3.423331  3.414898  3.461124  3.423183  3.405661  3.474047   3.456678   \n",
      "\n",
      "    gbr_lad  lassolars       rgf  \n",
      "0  3.033790   2.967263  3.037120  \n",
      "1  3.473452   3.392296  3.428089  \n",
      "2  2.571643   2.475812  2.541533  \n",
      "3  2.904787   2.915287  2.954800  \n",
      "4  3.480752   3.398572  3.460135  \n",
      "\n",
      "[5 rows x 621 columns]\n",
      "\n",
      "============================ TestData\n",
      "                                id          air_store_id visit_date  visitors  \\\n",
      "0  air_00a91d42b08b08d9_2017-04-23  air_00a91d42b08b08d9 2017-04-23       0.0   \n",
      "1  air_00a91d42b08b08d9_2017-04-24  air_00a91d42b08b08d9 2017-04-24       0.0   \n",
      "2  air_00a91d42b08b08d9_2017-04-25  air_00a91d42b08b08d9 2017-04-25       0.0   \n",
      "3  air_00a91d42b08b08d9_2017-04-26  air_00a91d42b08b08d9 2017-04-26       0.0   \n",
      "4  air_00a91d42b08b08d9_2017-04-27  air_00a91d42b08b08d9 2017-04-27       0.0   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_17  lgb_l2_meta_trees_25_500_31  \\\n",
      "0                     1.873078                     2.026239   \n",
      "1                     3.498896                     3.477146   \n",
      "2                     3.426053                     3.440528   \n",
      "3                     3.561045                     3.585462   \n",
      "4                     3.617715                     3.616938   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_57  lgb_l2_meta_trees_25_500_0  \\\n",
      "0                     2.115698                    1.720720   \n",
      "1                     3.473285                    3.377803   \n",
      "2                     3.404351                    3.357139   \n",
      "3                     3.521440                    3.533003   \n",
      "4                     3.572433                    3.557730   \n",
      "\n",
      "   lgb_l2_meta_trees_25_500_43  lgb_l2_meta_trees_25_500_108    ...     \\\n",
      "0                     1.730838                      2.141957    ...      \n",
      "1                     3.450049                      3.425937    ...      \n",
      "2                     3.296183                      3.360590    ...      \n",
      "3                     3.546641                      3.511807    ...      \n",
      "4                     3.589944                      3.565909    ...      \n",
      "\n",
      "   lgb_huber  lgb_fair       etr        en        rf    gbr_ls  gbr_huber  \\\n",
      "0   1.665468  1.951035  1.968729  1.412469  1.890063  2.128919   1.936107   \n",
      "1   3.387101  3.352597  3.234379  3.368305  3.259515  3.415575   3.346194   \n",
      "2   3.400502  3.272802  3.121437  3.318641  3.261824  3.364412   3.289267   \n",
      "3   3.556699  3.505066  3.480485  3.478223  3.441389  3.538937   3.448330   \n",
      "4   3.595512  3.507814  3.531847  3.566507  3.462476  3.533387   3.467651   \n",
      "\n",
      "    gbr_lad  lassolars       rgf  \n",
      "0  1.694391   1.451505  1.505389  \n",
      "1  3.391761   3.362605  3.426770  \n",
      "2  3.415623   3.313479  3.339142  \n",
      "3  3.561345   3.475259  3.557254  \n",
      "4  3.631246   3.550882  3.616640  \n",
      "\n",
      "[5 rows x 622 columns]\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:175: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: valid score 0.497014, holdout score 0.493867, valid length 45371\n",
      "saving for 0th fold data done.\n",
      "fold 1: valid score 0.488093, holdout score 0.493170, valid length 45371\n",
      "saving for 1th fold data done.\n",
      "fold 2: valid score 0.490437, holdout score 0.492607, valid length 45371\n",
      "saving for 2th fold data done.\n",
      "fold 3: valid score 0.493821, holdout score 0.492577, valid length 45370\n",
      "saving for 3th fold data done.\n",
      "fold 4: valid score 0.488796, holdout score 0.492406, valid length 45370\n",
      "saving for 4th fold data done.\n",
      "zip ../../data/l2/submit/top_188_214_204_meta_trees_submit_2018-01-19.zip ../../data/l2/submit/top_188_214_204_meta_trees_submit_2018-01-19.csv\n",
      "\n",
      "======================\n",
      "CV score 0.4916, Holdout score 0.4929, Elapsed time: 992.00s\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# Elastic Net Regression #\n",
    "#######################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os,sys\n",
    "import gc\n",
    "from sklearn import *\n",
    "import lightgbm\n",
    "\n",
    "drop_cols = ['id', 'visit_date', 'visitors', 'hpg_store_id', 'fold', 'air_store_id', \n",
    "             'air_reserved_visitors', 'hpg_reserved_visitors','reserved_visitors']\n",
    "\n",
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred) ** 0.5\n",
    "\n",
    "DataBaseDir = '../../data'\n",
    "OutputDir = '%s/l2/kfold' % DataBaseDir\n",
    "kfold = 5\n",
    "TopTreePair = 50000\n",
    "TopN = 10000\n",
    "threshold = 20\n",
    "SingleModels = ['lgb_l2', 'xgb_rmse','lgb_huber', 'lgb_fair', 'etr', 'en', 'rf',  'gbr_ls', 'gbr_huber', 'gbr_lad', 'lassolars', 'rgf']\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "#### load pair indexs1\n",
    "meta_tree_mod1 = 'meta_trees_25_500'\n",
    "InputDir1 = '%s/%s/l1/kfold' % (DataBaseDir, meta_tree_mod1)\n",
    "PairIndex1 = pd.read_csv('%s/%s/l1/pairs/%s_top%s_holdout.csv' % (DataBaseDir, meta_tree_mod1, meta_tree_mod1, TopTreePair))\n",
    "PairIndex1.columns = ['a', 'b']\n",
    "PairIndex1 = PairIndex1.loc[:TopN,]\n",
    "va = PairIndex1['a'].value_counts()\n",
    "vb = PairIndex1['b'].value_counts()\n",
    "vc = {}\n",
    "for k in va.keys():\n",
    "    vc[k] = va[k]\n",
    "for k in vb.keys():\n",
    "    if(k not in vc):\n",
    "        vc[k] = vb[k]\n",
    "    else:\n",
    "        vc[k] += vb[k]\n",
    "TopModelIndex1 = [v for v in vc if(vc[v] > threshold)]\n",
    "print('top %s models for %s.' % (len(TopModelIndex1), meta_tree_mod1))\n",
    "\n",
    "####\n",
    "meta_tree_mod2 = 'meta_trees_50_500'\n",
    "InputDir2 = '%s/%s/l1/kfold' % (DataBaseDir, meta_tree_mod2)\n",
    "PairIndex2 = pd.read_csv('%s/%s/l1/pairs/%s_top%s_holdout.csv' % (DataBaseDir, meta_tree_mod2, meta_tree_mod2, TopTreePair))\n",
    "PairIndex2.columns = ['a', 'b']\n",
    "PairIndex2 = PairIndex2.loc[:TopN,]\n",
    "va = PairIndex2['a'].value_counts()\n",
    "vb = PairIndex2['b'].value_counts()\n",
    "vc = {}\n",
    "for k in va.keys():\n",
    "    vc[k] = va[k]\n",
    "for k in vb.keys():\n",
    "    if(k not in vc):\n",
    "        vc[k] = vb[k]\n",
    "    else:\n",
    "        vc[k] += vb[k]\n",
    "TopModelIndex2 = [v for v in vc if(vc[v] > threshold)]\n",
    "print('top %s models for %s.' % (len(TopModelIndex2), meta_tree_mod2))\n",
    "\n",
    "####\n",
    "meta_tree_mod3 = 'meta_trees_75_500'\n",
    "InputDir3 = '%s/%s/l1/kfold' % (DataBaseDir, meta_tree_mod3)\n",
    "PairIndex3 = pd.read_csv('%s/%s/l1/pairs/%s_top%s_holdout.csv' % (DataBaseDir, meta_tree_mod3, meta_tree_mod3, TopTreePair))\n",
    "PairIndex3.columns = ['a', 'b']\n",
    "PairIndex3 = PairIndex3.loc[:TopN,]\n",
    "va = PairIndex3['a'].value_counts()\n",
    "vb = PairIndex3['b'].value_counts()\n",
    "vc = {}\n",
    "for k in va.keys():\n",
    "    vc[k] = va[k]\n",
    "for k in vb.keys():\n",
    "    if(k not in vc):\n",
    "        vc[k] = vb[k]\n",
    "    else:\n",
    "        vc[k] += vb[k]\n",
    "TopModelIndex3 = [v for v in vc if(vc[v] > threshold)]\n",
    "print('top %s models for %s.' % (len(TopModelIndex3), meta_tree_mod3))\n",
    "# sys.exit(1)\n",
    "#PairNum = len(PairIndex)\n",
    "#### load data\n",
    "valid_dfs = []\n",
    "holdout_dfs = []\n",
    "test_dfs = []\n",
    "join_keys = ['air_store_id', 'visit_date']\n",
    "start = time.time()\n",
    "strategy1 = 'lgb_l2_%s' % meta_tree_mod1\n",
    "strategy2 = 'lgb_l2_%s' % meta_tree_mod2\n",
    "strategy3 = 'lgb_l2_%s' % meta_tree_mod3\n",
    "\n",
    "for fold in range(kfold):\n",
    "    FoldInputDir = '%s/%s' % (InputDir1, fold)\n",
    "    FoldValid = pd.DataFrame()\n",
    "    FoldHoldout = pd.DataFrame()\n",
    "    FoldTest = pd.DataFrame()\n",
    "    for i in range(len(TopModelIndex1)):\n",
    "        colname = '%s_%s' % (strategy1, TopModelIndex1[i])\n",
    "        valid = pd.read_csv('%s/valid_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        holdout = pd.read_csv('%s/holdout_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        test = pd.read_csv('%s/test_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        if(i == 0):\n",
    "            FoldValid = valid\n",
    "            FoldHoldout = holdout\n",
    "            FoldTest = test\n",
    "        else:\n",
    "            FoldValid[colname] = valid[colname]\n",
    "            FoldHoldout[colname] = holdout[colname]\n",
    "            FoldTest[colname] = test[colname]\n",
    "    FoldInputDir = '%s/%s' % (InputDir2, fold)\n",
    "    for i in range(len(TopModelIndex2)):\n",
    "        colname = '%s_%s' % (strategy2, TopModelIndex2[i])\n",
    "        valid = pd.read_csv('%s/valid_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        holdout = pd.read_csv('%s/holdout_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        test = pd.read_csv('%s/test_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        FoldValid[colname] = valid[colname]\n",
    "        FoldHoldout[colname] = holdout[colname]\n",
    "        FoldTest[colname] = test[colname]\n",
    "    FoldInputDir = '%s/%s' % (InputDir3, fold)\n",
    "    for i in range(len(TopModelIndex3)):\n",
    "        colname = '%s_%s' % (strategy3, TopModelIndex3[i])\n",
    "        valid = pd.read_csv('%s/valid_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        holdout = pd.read_csv('%s/holdout_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        test = pd.read_csv('%s/test_%s.csv' % (FoldInputDir, colname), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        FoldValid[colname] = valid[colname]\n",
    "        FoldHoldout[colname] = holdout[colname]\n",
    "        FoldTest[colname] = test[colname]\n",
    "    FoldInputDir = '../../data/l1/kfold/%s' % (fold)\n",
    "    for i in range(len(SingleModels)):\n",
    "        valid = pd.read_csv('%s/valid_%s.csv' % (FoldInputDir, SingleModels[i]), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        holdout = pd.read_csv('%s/holdout_%s.csv' % (FoldInputDir, SingleModels[i]), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        test = pd.read_csv('%s/test_%s.csv' % (FoldInputDir, SingleModels[i]), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        FoldValid[SingleModels[i]] = valid[SingleModels[i]]\n",
    "        FoldHoldout[SingleModels[i]] = holdout[SingleModels[i]]\n",
    "        FoldTest[SingleModels[i]] = test[SingleModels[i]]\n",
    "    ###\n",
    "    FoldValid['fold'] = fold\n",
    "    valid_dfs.append(FoldValid)\n",
    "    holdout_dfs.append(FoldHoldout)\n",
    "    test_dfs.append(FoldTest)\n",
    "    end = time.time()\n",
    "    print('fold %s done, time elapsed %ss' % (fold, (end - start)))\n",
    "TrainData = pd.concat(valid_dfs, axis= 0, ignore_index= True)\n",
    "print('----------------- CHECK -------------')\n",
    "print('\\n============================ TrainData')\n",
    "print(TrainData.head(5))\n",
    "print('\\n============================ HoldoutData')\n",
    "print(holdout_dfs[0].head(5))\n",
    "print('\\n============================ TestData')\n",
    "print(test_dfs[0].head(5))\n",
    "print('-------------------------------------')\n",
    "# sys.exit(1)\n",
    "##### model selection with CV\n",
    "# score\n",
    "cv_score = .0\n",
    "holdout_score = .0\n",
    "# predict\n",
    "y_test_pred = 0\n",
    "for fold in range(kfold):\n",
    "    FoldData = {\n",
    "        'train': TrainData[TrainData['fold'] != fold],\n",
    "        'valid': TrainData[TrainData['fold'] == fold],\n",
    "        'holdout': holdout_dfs[fold],\n",
    "        'test': test_dfs[fold]\n",
    "    }\n",
    "    col = [c for c in FoldData['train'].columns if c not in drop_cols]\n",
    "    # train\n",
    "    model = linear_model.ElasticNet(alpha= 0.0001, l1_ratio= 0.2, max_iter= 400, tol= 1e-4, selection= 'random', random_state= 2017)\n",
    "    model.fit(FoldData['train'][col].astype(np.float32, copy=False), FoldData['train']['visitors'].values.astype(np.float32, copy=False))\n",
    "    # for valid\n",
    "    FoldData['valid'][strategy] = model.predict(FoldData['valid'][col])\n",
    "    rmsle_valid = RMSLE(FoldData['valid']['visitors'].values, FoldData['valid'][strategy])\n",
    "    cv_score += rmsle_valid\n",
    "    # for holdout\n",
    "    FoldData['holdout'][strategy] = model.predict(FoldData['holdout'][col])\n",
    "    rmsle_holdout = RMSLE(FoldData['holdout']['visitors'].values, FoldData['holdout'][strategy])\n",
    "    holdout_score += rmsle_holdout\n",
    "    # for test\n",
    "    FoldData['test'][strategy] = model.predict(FoldData['test'][col])\n",
    "    y_test_pred += FoldData['test'][strategy]\n",
    "\n",
    "    print('fold %s: valid score %.6f, holdout score %.6f, valid length %s' % (fold, rmsle_valid, rmsle_holdout, len(FoldData['valid'])))  \n",
    "    #### output\n",
    "    FoldOutputDir = '%s/%s' % (OutputDir, fold)\n",
    "    if(os.path.exists(FoldOutputDir) == False):\n",
    "        os.makedirs(FoldOutputDir)\n",
    "    for mod in FoldData.keys():\n",
    "        if(mod == 'train'):\n",
    "            continue\n",
    "        OutCols = []\n",
    "        if(mod == 'test'):\n",
    "            OutCols.append('id')\n",
    "        OutCols.extend(['air_store_id', 'visit_date', 'visitors', strategy])\n",
    "        OutputFile = '%s/%s_%s.csv' % (FoldOutputDir, mod, strategy)\n",
    "        OutFoldData = FoldData[mod][OutCols]\n",
    "        OutFoldData.to_csv(OutputFile, index= False)\n",
    "    print('saving for %sth fold data done.' % (fold))\n",
    "    \n",
    "y_test_pred /= kfold  # Average test set predictions\n",
    "cv_score /= kfold # Average valid set predictions\n",
    "holdout_score /= kfold # Average holdout set predictions\n",
    "\n",
    "# Create submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_dfs[0]['id']\n",
    "sub['visitors'] = np.expm1(y_test_pred)\n",
    "OutputStrategy = 'top_%s_%s_%s_meta_trees' % (len(TopModelIndex1), len(TopModelIndex2), len(TopModelIndex3))\n",
    "OutputFileName = '%s_submit_%s' % (OutputStrategy, datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "SubmitDir = '%s/l2/submit' % DataBaseDir\n",
    "if(os.path.exists(SubmitDir) == False):\n",
    "    os.makedirs(SubmitDir)\n",
    "sub.to_csv('%s/%s.csv' % (SubmitDir, OutputFileName), float_format='%.6f', index=False)\n",
    "print('zip %s/%s.zip %s/%s.csv' % (SubmitDir, OutputFileName, SubmitDir, OutputFileName))\n",
    "os.system('zip %s/%s.zip %s/%s.csv' % (SubmitDir, OutputFileName, SubmitDir, OutputFileName))\n",
    "\n",
    "finish_time = datetime.datetime.now()\n",
    "elapsed = (finish_time - start_time).seconds\n",
    "print('\\n======================')\n",
    "print(\"CV score %.4f, Holdout score %.4f, Elapsed time: %.2fs\" % (cv_score, holdout_score, elapsed))\n",
    "print('======================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
