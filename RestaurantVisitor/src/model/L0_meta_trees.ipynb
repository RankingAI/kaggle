{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T06:32:12.866775Z",
     "start_time": "2018-01-31T06:29:50.361995Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2698: DtypeWarning: Columns (27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data done. time elapsed 65.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: valid score 0.577717, holdout score 0.575676, valid length 45371\n",
      "fold 1: valid score 0.571019, holdout score 0.574696, valid length 45371\n",
      "fold 2: valid score 0.574212, holdout score 0.574440, valid length 45371\n",
      "fold 3: valid score 0.579512, holdout score 0.576302, valid length 45370\n",
      "fold 4: valid score 0.576145, holdout score 0.575380, valid length 45370\n",
      "\n",
      "======================\n",
      "CV score 0.5757, Holdout score 0.5753, Elapsed time: 86.91s\n",
      "======================\n",
      "\n",
      "------- part 0 done. time elapsed 86.91s ----------\n",
      "\n",
      "fold 0: valid score 0.544778, holdout score 0.538225, valid length 45371\n",
      "fold 1: valid score 0.535579, holdout score 0.537350, valid length 45371\n",
      "fold 2: valid score 0.539769, holdout score 0.537341, valid length 45371\n",
      "fold 3: valid score 0.545230, holdout score 0.537498, valid length 45370\n",
      "fold 4: valid score 0.538406, holdout score 0.537679, valid length 45370\n",
      "\n",
      "======================\n",
      "CV score 0.5408, Holdout score 0.5376, Elapsed time: 104.65s\n",
      "======================\n",
      "\n",
      "------- part 1 done. time elapsed 104.65s ----------\n",
      "\n",
      "fold 0: valid score 0.520617, holdout score 0.513233, valid length 45371\n",
      "fold 1: valid score 0.513324, holdout score 0.512963, valid length 45371\n",
      "fold 2: valid score 0.517021, holdout score 0.512959, valid length 45371\n",
      "fold 3: valid score 0.520794, holdout score 0.512533, valid length 45370\n",
      "fold 4: valid score 0.516369, holdout score 0.513868, valid length 45370\n",
      "\n",
      "======================\n",
      "CV score 0.5176, Holdout score 0.5131, Elapsed time: 123.02s\n",
      "======================\n",
      "\n",
      "------- part 2 done. time elapsed 123.02s ----------\n",
      "\n",
      "fold 0: valid score 0.551373, holdout score 0.544546, valid length 45371\n",
      "fold 1: valid score 0.543108, holdout score 0.545419, valid length 45371\n",
      "fold 2: valid score 0.547448, holdout score 0.544876, valid length 45371\n",
      "fold 3: valid score 0.551962, holdout score 0.544603, valid length 45370\n",
      "fold 4: valid score 0.547845, holdout score 0.545445, valid length 45370\n",
      "\n",
      "======================\n",
      "CV score 0.5483, Holdout score 0.5450, Elapsed time: 141.78s\n",
      "======================\n",
      "\n",
      "------- part 3 done. time elapsed 141.78s ----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# meta-tree models    #\n",
    "#######################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os,sys\n",
    "import gc\n",
    "from sklearn import *\n",
    "import lightgbm\n",
    "import random\n",
    "import json\n",
    "\n",
    "drop_cols = ['id', 'visit_date', 'visitors', 'hpg_store_id', 'fold', 'air_store_id', \n",
    "             'air_store_id_encoded', 'hpg_store_id_encoded', \n",
    "             'air_reserved_visitors', 'hpg_reserved_visitors','reserved_visitors']    \n",
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred) ** 0.5\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'rmsle', RMSLE(labels, preds), True\n",
    "\n",
    "start = time.time()\n",
    "DataBaseDir = '../../data'\n",
    "InputDir = '%s/l0/kfold' % DataBaseDir\n",
    "MetaInputDir = '%s/meta/kfold' % DataBaseDir\n",
    "kfold = 5\n",
    "meta_ratio = 0.25\n",
    "use_selected = True\n",
    "TreeNum = 200\n",
    "#### load data\n",
    "valid_dfs = []\n",
    "holdout_dfs = []\n",
    "test_dfs = []\n",
    "meta_feats = ['nn_ef', 'knn_2', 'knn_4', 'knn_8', 'knn_16', 'knn_32', 'knn_64', 'knn_128', 'knn_256', 'knn_512', 'knn_1024']\n",
    "for fold in range(kfold):\n",
    "    FoldInputDir = '%s/%s' % (InputDir, fold)\n",
    "    valid = pd.read_csv('%s/valid.csv' % FoldInputDir, parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "    holdout = pd.read_csv('%s/holdout.csv' % FoldInputDir, parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "    test = pd.read_csv('%s/test.csv' % FoldInputDir, parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "    for t in meta_feats:\n",
    "        # load meta-feature\n",
    "        FoldOutputDir = '%s/%s' % (MetaInputDir, fold)\n",
    "        valid_cb_ef = pd.read_csv('%s/valid_%s.csv' % (FoldOutputDir, t), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        holdout_cb_ef = pd.read_csv('%s/holdout_%s.csv' % (FoldOutputDir, t), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        test_cb_ef = pd.read_csv('%s/test_%s.csv' % (FoldOutputDir, t), parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "        # concate\n",
    "        valid = pd.concat([valid, valid_cb_ef[[t]]], axis= 1)\n",
    "        holdout = pd.concat([holdout, holdout_cb_ef[[t]]], axis= 1)\n",
    "        test = pd.concat([test, test_cb_ef[[t]]], axis= 1)\n",
    "    #\n",
    "    valid['fold'] = fold\n",
    "    valid_dfs.append(valid)\n",
    "    holdout_dfs.append(holdout)\n",
    "    test_dfs.append(test)\n",
    "TrainData = pd.concat(valid_dfs, axis= 0, ignore_index= True)\n",
    "end = time.time()\n",
    "print('Load data done. time elapsed %.2fs' % (end - start))\n",
    "##### model selection with CV\n",
    "# score\n",
    "holdout_score = .0\n",
    "# parameters\n",
    "params = {\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"objective\": \"regression_l2\",\n",
    "    \"lambda_l2\": [200],\n",
    "    \"learning_rate\": [0.15],\n",
    "    \n",
    "    \"num_iterations\": 100,\n",
    "#     \"min_data_in_leaf\": 150,\n",
    "    #'num_leaves': 255,\n",
    "    \"max_depth\": 6,\n",
    "\n",
    "    \"feature_fraction\": 0.6,\n",
    "    \"bagging_fraction\": 0.85,\n",
    "    \"bagging_freq\": 20,\n",
    "    \"min_hessian\": 0.001,\n",
    "    \n",
    "    \"verbose\": False,\n",
    "    \"max_bin\": 63,\n",
    "}\n",
    "total_cols = []\n",
    "## feature options\n",
    "if(use_selected):\n",
    "    with open('../../data/gfs/all/good_features_2018-01-30.txt', 'r') as i_file:\n",
    "        for line in i_file:\n",
    "            total_cols.append(line.rstrip())\n",
    "    i_file.close()\n",
    "    others = ['nn_ef']#, 'latitude_x', 'latitude_y', 'longitude_x', 'longitude_y', 'lon_plus_lat_x', 'var_max_long_x', 'var_max_lat_x']\n",
    "    total_cols.extend(others)\n",
    "K = int(meta_ratio * len(total_cols))\n",
    "for idx in range(TreeNum):\n",
    "    strategy = 'lgb_l2_meta_trees_%s_%s_%s' % (int(meta_ratio * 100), TreeNum, idx)\n",
    "    selected_cols = [total_cols[i] for i in sorted(np.random.choice(range(len(total_cols)), K, replace= False))]\n",
    "    OutputDir = '%s/meta_trees_%s_%s/l1/kfold' % (DataBaseDir, int(meta_ratio * 100), TreeNum)\n",
    "    if(os.path.exists(OutputDir) == False):\n",
    "        os.makedirs(OutputDir)\n",
    "    # save feature space\n",
    "    with open('%s/sub_feats.txt' % OutputDir, 'w') as o_file:\n",
    "        for feat in selected_cols:\n",
    "            o_file.write('%s\\n' % feat)\n",
    "    o_file.close()\n",
    "    ## retrain and store\n",
    "    cv_score = .0\n",
    "    holdout_score = .0\n",
    "    for fold in range(kfold):\n",
    "        FoldData = {\n",
    "            'train': TrainData[TrainData['fold'] != fold],\n",
    "            'valid': TrainData[TrainData['fold'] == fold],\n",
    "            'holdout': holdout_dfs[fold],\n",
    "            'test': test_dfs[fold]\n",
    "        }\n",
    "        # train\n",
    "        dtrain = lightgbm.Dataset(FoldData['train'][selected_cols], label= FoldData['train']['visitors'], silent= True, free_raw_data= True)\n",
    "        dvalid = lightgbm.Dataset(FoldData['valid'][selected_cols], FoldData['valid']['visitors'], reference=dtrain)\n",
    "        param = {\n",
    "            'boosting': 'gbdt',\n",
    "            'objective': 'regression_l2',\n",
    "                \n",
    "            'lambda_l2': params['lambda_l2'][0],\n",
    "            'learning_rate': params['learning_rate'][0],\n",
    "                        \n",
    "            'num_iterations': params['num_iterations'],\n",
    "            'feature_fraction': params['feature_fraction'],\n",
    "            'bagging_fraction': params['bagging_fraction'],\n",
    "            'bagging_freq': params['bagging_freq'],\n",
    "            'min_hessian': params['min_hessian'],\n",
    "            'max_bin': params['max_bin'],\n",
    "        }\n",
    "        model = lightgbm.train(param, \n",
    "                        train_set= dtrain, \n",
    "                        num_boost_round= params['num_iterations'], \n",
    "                        valid_sets= dvalid,\n",
    "                        feval= evalerror,\n",
    "                        verbose_eval= False,\n",
    "                        early_stopping_rounds= 100)        \n",
    "        # for valid\n",
    "        FoldData['valid'][strategy] = model.predict(FoldData['valid'][selected_cols])\n",
    "        rmsle_valid = RMSLE(FoldData['valid']['visitors'].values, FoldData['valid'][strategy])\n",
    "        cv_score += rmsle_valid\n",
    "        # for holdout\n",
    "        FoldData['holdout'][strategy] = model.predict(FoldData['holdout'][selected_cols])\n",
    "        rmsle_holdout = RMSLE(FoldData['holdout']['visitors'].values, FoldData['holdout'][strategy])\n",
    "        holdout_score += rmsle_holdout\n",
    "        # for test\n",
    "        FoldData['test'][strategy] = model.predict(FoldData['test'][selected_cols])\n",
    "\n",
    "        print('fold %s: valid score %.6f, holdout score %.6f, valid length %s' % (fold, rmsle_valid, rmsle_holdout, len(FoldData['valid'])))  \n",
    "        #### output\n",
    "        FoldOutputDir = '%s/%s' % (OutputDir, fold)\n",
    "        if(os.path.exists(FoldOutputDir) == False):\n",
    "            os.makedirs(FoldOutputDir)\n",
    "        for mod in FoldData.keys():\n",
    "            if(mod == 'train'):\n",
    "                continue\n",
    "            OutCols = []\n",
    "            if(mod == 'test'):\n",
    "                OutCols.append('id')\n",
    "            OutCols.extend(['air_store_id', 'visit_date', 'visitors', strategy])\n",
    "            OutputFile = '%s/%s_%s.csv' % (FoldOutputDir, mod, strategy)\n",
    "            OutFoldData = FoldData[mod][OutCols]\n",
    "            OutFoldData.to_csv(OutputFile, index= False)\n",
    "    \n",
    "    cv_score /= kfold # Average valid set predictions\n",
    "    holdout_score /= kfold # Average holdout set predictions\n",
    "\n",
    "    end = time.time()\n",
    "    print('\\n======================')\n",
    "    print(\"CV score %.4f, Holdout score %.4f, Elapsed time: %.2fs\" % (cv_score, holdout_score, (end - start)))\n",
    "    print('======================\\n')\n",
    "    \n",
    "    with open('%s/result.txt' % OutputDir, 'w') as o_file:\n",
    "        o_file.write('cv score %.4f, holdout score %.4f' % (cv_score, holdout_score))\n",
    "    o_file.close()\n",
    "    \n",
    "    print('------- part %s done. time elapsed %.2fs ----------\\n' % (idx, (end - start)))\n",
    "    if(idx == 3):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
