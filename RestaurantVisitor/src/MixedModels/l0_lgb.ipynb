{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T15:23:44.595840Z",
     "start_time": "2018-01-08T15:23:44.538384Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import dill as pickle\n",
    "\n",
    "class DataUtil2:\n",
    "    \"\"\"\"\"\"\n",
    "    @classmethod\n",
    "    def load(cls, file, format, date_cols= None):\n",
    "        \"\"\"\"\"\"\n",
    "        data = ''\n",
    "        if(format== 'csv'):\n",
    "            data = pd.read_csv(file, parse_dates= date_cols)\n",
    "        elif(format== 'json'):\n",
    "            with open(file, 'r') as i_file:\n",
    "                data = json.load(file)\n",
    "            i_file.close()\n",
    "        elif(format== 'pkl'):\n",
    "            with open(file, 'rb') as i_file:\n",
    "                data = pickle.load(i_file)\n",
    "            i_file.close()\n",
    "        elif(format == 'hdf'):\n",
    "            data = pd.read_hdf(path_or_buf= file, key='undefined')\n",
    "\n",
    "        return  data\n",
    "\n",
    "    @classmethod\n",
    "    def save(cls, data, file, format, precision= 8):\n",
    "        \"\"\"\"\"\"\n",
    "        if(format == 'csv'):\n",
    "            data.to_csv(file, float_format= '%%.%df' % precision, index= False)\n",
    "        elif(format == 'json'):\n",
    "            with open(file, 'w') as o_file:\n",
    "                json.dump(data, o_file, ensure_ascii= True, indent= 4)\n",
    "            o_file.close()\n",
    "        elif(format == 'pkl'):\n",
    "            with open(file, 'wb') as o_file:\n",
    "                pickle.dump(data, o_file, -1)\n",
    "            o_file.close()\n",
    "        elif(format== 'hdf'):\n",
    "            data.to_hdf(path_or_buf= file, key='undefined', mode='w', complib='blosc')\n",
    "\n",
    "        return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-08T15:32:53.724311Z",
     "start_time": "2018-01-08T15:23:44.597949Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/lightgbm/engine.py:99: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/lightgbm/basic.py:642: UserWarning: max_bin keyword has been found in `params` and will be ignored. Please use max_bin argument of the Dataset constructor to pass this parameter.\n",
      "  'Please use {0} argument of the Dataset constructor to pass this parameter.'.format(key))\n",
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/lightgbm/basic.py:648: LGBMDeprecationWarning: The `max_bin` parameter is deprecated and will be removed in 2.0.12 version. Please use `params` to pass this parameter.\n",
      "  'Please use `params` to pass this parameter.', LGBMDeprecationWarning)\n",
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:114: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 200.000000, learning rate 0.800000, depth 8, cv score 0.50779\n",
      "running for params, l2 200, lr 0.8, depth 8 done, time elapsed 17.71s\n",
      "l2 200.000000, learning rate 0.800000, depth 12, cv score 0.50843\n",
      "running for params, l2 200, lr 0.8, depth 12 done, time elapsed 35.33s\n",
      "l2 200.000000, learning rate 0.800000, depth 16, cv score 0.50890\n",
      "running for params, l2 200, lr 0.8, depth 16 done, time elapsed 53.89s\n",
      "l2 200.000000, learning rate 0.200000, depth 8, cv score 0.50072\n",
      "running for params, l2 200, lr 0.2, depth 8 done, time elapsed 72.22s\n",
      "l2 200.000000, learning rate 0.200000, depth 12, cv score 0.50079\n",
      "running for params, l2 200, lr 0.2, depth 12 done, time elapsed 91.36s\n",
      "l2 200.000000, learning rate 0.200000, depth 16, cv score 0.50042\n",
      "running for params, l2 200, lr 0.2, depth 16 done, time elapsed 110.38s\n",
      "l2 200.000000, learning rate 0.020000, depth 8, cv score 0.51387\n",
      "running for params, l2 200, lr 0.02, depth 8 done, time elapsed 132.92s\n",
      "l2 200.000000, learning rate 0.020000, depth 12, cv score 0.51382\n",
      "running for params, l2 200, lr 0.02, depth 12 done, time elapsed 155.36s\n",
      "l2 200.000000, learning rate 0.020000, depth 16, cv score 0.51382\n",
      "running for params, l2 200, lr 0.02, depth 16 done, time elapsed 178.36s\n",
      "l2 20.000000, learning rate 0.800000, depth 8, cv score 0.51542\n",
      "running for params, l2 20, lr 0.8, depth 8 done, time elapsed 194.42s\n",
      "l2 20.000000, learning rate 0.800000, depth 12, cv score 0.51620\n",
      "running for params, l2 20, lr 0.8, depth 12 done, time elapsed 210.39s\n",
      "l2 20.000000, learning rate 0.800000, depth 16, cv score 0.51586\n",
      "running for params, l2 20, lr 0.8, depth 16 done, time elapsed 226.36s\n",
      "l2 20.000000, learning rate 0.200000, depth 8, cv score 0.49999\n",
      "running for params, l2 20, lr 0.2, depth 8 done, time elapsed 242.86s\n",
      "l2 20.000000, learning rate 0.200000, depth 12, cv score 0.50033\n",
      "running for params, l2 20, lr 0.2, depth 12 done, time elapsed 259.44s\n",
      "l2 20.000000, learning rate 0.200000, depth 16, cv score 0.50028\n",
      "running for params, l2 20, lr 0.2, depth 16 done, time elapsed 276.17s\n",
      "l2 20.000000, learning rate 0.020000, depth 8, cv score 0.51283\n",
      "running for params, l2 20, lr 0.02, depth 8 done, time elapsed 297.53s\n",
      "l2 20.000000, learning rate 0.020000, depth 12, cv score 0.51275\n",
      "running for params, l2 20, lr 0.02, depth 12 done, time elapsed 319.76s\n",
      "l2 20.000000, learning rate 0.020000, depth 16, cv score 0.51276\n",
      "running for params, l2 20, lr 0.02, depth 16 done, time elapsed 343.10s\n",
      "l2 1.000000, learning rate 0.800000, depth 8, cv score 0.52363\n",
      "running for params, l2 1, lr 0.8, depth 8 done, time elapsed 358.51s\n",
      "l2 1.000000, learning rate 0.800000, depth 12, cv score 0.52540\n",
      "running for params, l2 1, lr 0.8, depth 12 done, time elapsed 374.03s\n",
      "l2 1.000000, learning rate 0.800000, depth 16, cv score 0.52489\n",
      "running for params, l2 1, lr 0.8, depth 16 done, time elapsed 389.49s\n",
      "l2 1.000000, learning rate 0.200000, depth 8, cv score 0.50076\n",
      "running for params, l2 1, lr 0.2, depth 8 done, time elapsed 406.37s\n",
      "l2 1.000000, learning rate 0.200000, depth 12, cv score 0.50037\n",
      "running for params, l2 1, lr 0.2, depth 12 done, time elapsed 423.23s\n",
      "l2 1.000000, learning rate 0.200000, depth 16, cv score 0.50039\n",
      "running for params, l2 1, lr 0.2, depth 16 done, time elapsed 440.96s\n",
      "l2 1.000000, learning rate 0.020000, depth 8, cv score 0.51256\n",
      "running for params, l2 1, lr 0.02, depth 8 done, time elapsed 462.04s\n",
      "l2 1.000000, learning rate 0.020000, depth 12, cv score 0.51253\n",
      "running for params, l2 1, lr 0.02, depth 12 done, time elapsed 484.10s\n",
      "l2 1.000000, learning rate 0.020000, depth 16, cv score 0.51253\n",
      "running for params, l2 1, lr 0.02, depth 16 done, time elapsed 506.43s\n",
      "grid search done, time elapsed 506.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanpingzhou/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0: valid score 0.538332, holdout score 0.530405, valid length 45371\n",
      "fold 1: valid score 0.531885, holdout score 0.531837, valid length 45371\n",
      "fold 2: valid score 0.536929, holdout score 0.530826, valid length 45371\n",
      "fold 3: valid score 0.539145, holdout score 0.530691, valid length 45370\n",
      "fold 4: valid score 0.534091, holdout score 0.531284, valid length 45370\n",
      "\n",
      "======================\n",
      "CV score 0.5361, Holdout score 0.5310, Elapsed time: 541.90s\n",
      "======================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# LigthGBM Regression #\n",
    "#######################\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os,sys\n",
    "import gc\n",
    "from sklearn import *\n",
    "import lightgbm\n",
    "import random\n",
    "\n",
    "drop_cols = ['id', 'visit_date', 'visitors', 'hpg_store_id', 'fold', 'air_store_id']\n",
    "\n",
    "cate_cols = ['store_id_encoded', 'area_name', 'city', 'genre_name']\n",
    "cate_feats = ['dow', 'hol_days', 'day', 'pom', 'prev_is_holiday', 'next_is_holiday', \n",
    "              'wom', 'woy', 'is_weekends', 'holiday_flg', 'month', 'is_up_corner']\n",
    "for mod in ['air', 'hpg']:\n",
    "    cate_feats.extend(['%s_%s' % (mod, c) for c in cate_cols])\n",
    "    \n",
    "def RMSLE(y, pred):\n",
    "    return metrics.mean_squared_error(y, pred) ** 0.5\n",
    "\n",
    "DataBaseDir = '../../../data'\n",
    "InputDir = '%s/l0/kfold' % DataBaseDir\n",
    "kfold = 5\n",
    "strategy = 'lgb_l2'\n",
    "#### load data\n",
    "valid_dfs = []\n",
    "holdout_dfs = []\n",
    "test_dfs = []\n",
    "for fold in range(kfold):\n",
    "    FoldInputDir = '%s/%s' % (InputDir, fold)\n",
    "    valid = pd.read_csv('%s/valid.csv' % FoldInputDir, parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "    holdout = pd.read_csv('%s/holdout.csv' % FoldInputDir, parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "    test = pd.read_csv('%s/test.csv' % FoldInputDir, parse_dates= ['visit_date']).reset_index(drop= True)\n",
    "    #\n",
    "    valid['fold'] = fold\n",
    "    valid_dfs.append(valid)\n",
    "    holdout_dfs.append(holdout)\n",
    "    test_dfs.append(test)\n",
    "TrainData = pd.concat(valid_dfs, axis= 0, ignore_index= True)\n",
    "##### model selection with CV\n",
    "# score\n",
    "cv_score = .0\n",
    "holdout_score = .0\n",
    "# parameters\n",
    "params = {\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"objective\": \"regression_l2\",\n",
    "    \"lambda_l2\": [500, 200, 100],\n",
    "    \n",
    "    \"num_iterations\": 150,\n",
    "    \"learning_rate\": [0.8, 0.4, 0.2],\n",
    "    \"min_data_in_leaf\": 20,\n",
    "    'num_leaves': 255,\n",
    "    \"max_depth\": [12, 16, 20],\n",
    "\n",
    "    \"feature_fraction\": 0.90,\n",
    "    \"bagging_fraction\": 0.85,\n",
    "    \"bagging_freq\": 20,\n",
    "    \"min_hessian\": 0.001,\n",
    "\n",
    "    \"max_bin\": 63,\n",
    "}\n",
    "col = [c for c in TrainData.columns if c not in drop_cols]\n",
    "K = int(0.3 * len(col))\n",
    "selected_cols = [ col[i] for i in sorted(random.sample(range(len(col)), K))]\n",
    "OutputDir = '%s/MM/l1/0' % DataBaseDir\n",
    "if(os.path.exists(OutputDir) == False):\n",
    "    os.makedirs(OutputDir)\n",
    "with open('%s/sub_feats.txt' % OutputDir, 'w') as o_file:\n",
    "    for feat in selected_cols:\n",
    "        o_file.write('%s\\n' % feat)\n",
    "o_file.close()\n",
    "start = time.time()\n",
    "##\n",
    "BestParmas = {}\n",
    "BestScore = 1.0\n",
    "for l2 in params['lambda_l2']:\n",
    "    for lr in params['learning_rate']:\n",
    "        for depth in params['max_depth']:\n",
    "            cv_rmsle = .0\n",
    "            for fold in range(kfold):\n",
    "                FoldData = {\n",
    "                    'train': TrainData[TrainData['fold'] != fold],\n",
    "                    'valid': TrainData[TrainData['fold'] == fold]\n",
    "                }\n",
    "                col = [c for c in FoldData['train'].columns if(c not in drop_cols)]\n",
    "                d_cv = lightgbm.Dataset(FoldData['train'][col], \n",
    "                                        label= FoldData['train']['visitors'], \n",
    "                                        max_bin= params['max_bin'], \n",
    "                                        silent= True, \n",
    "                                        free_raw_data= True)\n",
    "                param = {\n",
    "                    'boosting': 'gbdt',\n",
    "                    'objective': 'regression_l2',\n",
    "                        \n",
    "                    'lambda_l2': l2,\n",
    "                    'learning_rate': lr,\n",
    "                    'max_depth': depth,\n",
    "\n",
    "                    'num_iterations': params['num_iterations'],\n",
    "                    'feature_fraction': params['feature_fraction'],\n",
    "                    'bagging_fraction': params['bagging_fraction'],\n",
    "                    'bagging_freq': params['bagging_freq'],\n",
    "                    'min_hessian': params['min_hessian'],\n",
    "                    'max_bin': params['max_bin'],\n",
    "                }\n",
    "                model = lightgbm.train(param, d_cv)\n",
    "                FoldData['valid'][strategy] = model.predict(FoldData['valid'][col])\n",
    "                rmsle_valid = RMSLE(FoldData['valid']['visitors'], FoldData['valid'][strategy])\n",
    "                cv_rmsle += rmsle_valid\n",
    "            cv_rmsle /= kfold\n",
    "            if(cv_rmsle < BestScore):\n",
    "                BestScore = cv_rmsle\n",
    "                BestParmas['lambda_l2'] = l2\n",
    "                BestParmas['learning_rate'] = lr\n",
    "                BestParmas['max_depth'] = depth\n",
    "            end = time.time()\n",
    "            print('running for params, l2 %s, lr %s, depth %s done, cv score %.5f, time elapsed %.2fs' % (l2, lr, depth, cv_rmsle, (end - start)))\n",
    "end = time.time()\n",
    "print('grid search done, time elapsed %.2fs' % (end - start))            \n",
    "## retrain and store\n",
    "for fold in range(kfold):\n",
    "    FoldData = {\n",
    "        'train': TrainData[TrainData['fold'] != fold],\n",
    "        'valid': TrainData[TrainData['fold'] == fold],\n",
    "        'holdout': holdout_dfs[fold],\n",
    "        'test': test_dfs[fold]\n",
    "    }\n",
    "    # train\n",
    "    d_cv = lightgbm.Dataset(FoldData['train'][selected_cols], label= FoldData['train']['visitors'].values, max_bin= params['max_bin'], silent= True, free_raw_data= True)\n",
    "    param = {\n",
    "        'boosting': 'gbdt',\n",
    "        'objective': 'regression_l2',\n",
    "                \n",
    "        'lambda_l2': BestParmas['lambda_l2'],\n",
    "        'learning_rate': BestParmas['learning_rate'],\n",
    "        'max_depth': BestParmas['max_depth'],\n",
    "                        \n",
    "        'num_iterations': 500,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.9,\n",
    "        'bagging_freq': 20,\n",
    "        'min_hessian': 0.001,\n",
    "        'max_bin': 63\n",
    "    }\n",
    "    model = lightgbm.train(param, d_cv)\n",
    "    # for valid\n",
    "    FoldData['valid'][strategy] = model.predict(FoldData['valid'][selected_cols])\n",
    "    rmsle_valid = RMSLE(FoldData['valid']['visitors'].values, FoldData['valid'][strategy])\n",
    "    cv_score += rmsle_valid\n",
    "    # for holdout\n",
    "    FoldData['holdout'][strategy] = model.predict(FoldData['holdout'][selected_cols])\n",
    "    rmsle_holdout = RMSLE(FoldData['holdout']['visitors'].values, FoldData['holdout'][strategy])\n",
    "    holdout_score += rmsle_holdout\n",
    "    # for test\n",
    "    FoldData['test'][strategy] = model.predict(FoldData['test'][selected_cols])\n",
    "\n",
    "    print('fold %s: valid score %.6f, holdout score %.6f, valid length %s' % (fold, rmsle_valid, rmsle_holdout, len(FoldData['valid'])))  \n",
    "    #### output\n",
    "    FoldOutputDir = '%s/kfold/%s' % (OutputDir, fold)\n",
    "    if(os.path.exists(FoldOutputDir) == False):\n",
    "        os.makedirs(FoldOutputDir)\n",
    "    for mod in FoldData.keys():\n",
    "        if(mod == 'train'):\n",
    "            continue\n",
    "        OutCols = []\n",
    "        if(mod == 'test'):\n",
    "            OutCols.append('id')\n",
    "        OutCols.extend(['air_store_id', 'visit_date', 'visitors', strategy])\n",
    "        OutputFile = '%s/%s_%s.csv' % (FoldOutputDir, mod, strategy)\n",
    "        OutFoldData = FoldData[mod][OutCols]\n",
    "        OutFoldData.to_csv(OutputFile, index= False)\n",
    "    \n",
    "cv_score /= kfold # Average valid set predictions\n",
    "holdout_score /= kfold # Average holdout set predictions\n",
    "\n",
    "end = time.time()\n",
    "print('\\n======================')\n",
    "print(\"CV score %.4f, Holdout score %.4f, Elapsed time: %.2fs\" % (cv_score, holdout_score, (end - start)))\n",
    "print('======================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
